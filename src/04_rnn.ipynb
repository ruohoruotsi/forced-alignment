{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RNN prototype\n",
    "\n",
    "From the previous notebooks the following data was created:\n",
    "\n",
    "1. audio signal resampled to 16kHz (mono)\n",
    "1. segmentation of the audio signal into speech- and pause-segments derived from the raw data or through WebRTC\n",
    "1. spectrograms or MFCC of the audio signal to use as training data\n",
    "1. transcriptions for the raw speech segments in original and normalized form\n",
    "\n",
    "We can now train an RNN that will learn the relationship between an audio signal and its textual representation using the [CTC loss function](https://www.cs.toronto.edu/~graves/icml_2006.pdf) as described in the [introduction](00_introduction.ipynb).\n",
    "\n",
    "The spectrograms of speech segments (3.) and their transcriptions (4.) are called the _labelled data_. This data consists of the input data  `X` and the labels `Y`. To train the network we use only a part of it. This part is referred to as **training set**. To prevent overfitting on this set we use another part of the labelled data to form a **validation/dev set**.\n",
    "\n",
    "This notebook describes the training of a RNN prototype. The prototype does not represent a valid RNN that can be used for RNN. Instead, it is trained on various input. The results are then compared in order to gain knowledge about the influence of different properties of the input on the result.\n",
    "\n",
    "The goal of this process is to get valuable information to train a real RNN later. If the training is successful, the RNN will be able to output a transcription for unknown instances that is roughly equivalent to the actual transcription. We can evaluate the RNN's performance by comparing its output with the actual transcription on a **test-set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = r'E:/' # define the path to where the corpus files are located!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, some imports and some helper functions need to be defined before we start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from util.corpus_util import *\n",
    "from util.audio_util import *\n",
    "\n",
    "rl_corpus_root = os.path.join(corpus_root, 'readylingua-corpus')\n",
    "ls_corpus_root = os.path.join(corpus_root, 'librispeech-corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "Since the pronunciation of a given piece of text is highly dependent on the language, we train the RNN only on a specific language of the corpus at a time. Therefore different RNN need to be trained for different languages. \n",
    "\n",
    "To show the impact of various properties of the training set, the following Proof of Concepts (PoC) are created:\n",
    "\n",
    "* **PoC #1 (benchmark)**: We start with a very simple RNN that is only trained on five speech segments from a single corpus entry in German and observe the training progress.\n",
    "* **PoC #2 (convergence for German)**: We then compare the results by extending this example. The same RNN is trained on the same corpus entry, but this time with all speech segments. This should give us some hints as to how additional input from the same distribution will influence convergence during the learning progress.\n",
    "* **PoC #3 (language, sequence length)**: The same RNN is trained again with only five speech segments, but those are taken from a corpus entry in a different language (English instead of German). From the result we hope to infer some information about how robust the RNN architecture is to various languages.\n",
    "* **PoC #4 (convergence for English)**: The same RNN is trained again with all speech segments of the English corpus Entry. Comparison with PoC#2 should give us some information about the influence of language on convergence.\n",
    "\n",
    "The RNN is trained with both spectrograms and MFCC as features. Comparing the performance between both types of features should give some information about what features are better suited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_corpus_de = load_corpus(rl_corpus_root)(languages='de')\n",
    "rl_corpus_de.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = rl_corpus_de['edznachrichten180111']\n",
    "corpus_entry.summary()\n",
    "\n",
    "corpus_entry_nonnumeric = corpus_entry(numeric=False)\n",
    "corpus_entry_nonnumeric.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN architecture\n",
    "\n",
    "We train an RNN with the following architecture (inspired by [this repository](https://github.com/philipperemy/tensorflow-ctc-speech-recognition)):\n",
    "\n",
    "* number of features: 13\n",
    "* number of hidden layers: 1\n",
    "* RNN-cell type: LSTM\n",
    "\n",
    "### RNN cost\n",
    "We measure the cost in two ways:\n",
    "\n",
    "* CTC-cost\n",
    "* Label Error Rate (LER)\n",
    "\n",
    "#### CTC cost\n",
    "The CTC cost is calculated as follows:\n",
    "\n",
    "tbd...\n",
    "\n",
    "#### Label Error Rate (LER)\n",
    "The LER is defined as the [edit distance](https://www.tensorflow.org/api_docs/python/tf/edit_distance) between prediction (_hypothesis_) and actual labels (_truth_), also called the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance). Observe for example the LER for the hypothesis `hello` and the truth `hallo`: The two strings differ in 1 of 5 characters, therefore the LER is `0.2`.\n",
    "\n",
    "The LER can also be computed for strings of different lengths. The following table gives an overview of a few samples.\n",
    "\n",
    "| Hypothesis | Truth | LER |\n",
    "|---|---|---|\n",
    "| 'hello' | 'hallo' | 0.2\n",
    "| 'hell' | 'hallo' | 0.4\n",
    "| 'hel' | 'hallo' | 0.6\n",
    "| 'helloo' | 'hallo' | 0.4\n",
    "| 'hellooo' | 'hallo' | 0.6\n",
    "| 'helo' | 'hallo' | 0.4\n",
    "| 'heloo' | 'hallo' | 0.4\n",
    "| 'helooo' | 'hallo' | 0.6\n",
    "| 'allo' | 'hallo' | 0.2\n",
    "| 'elo' | 'hallo' | 0.6\n",
    "\n",
    "You can also execute the cell below to see how the values are calculated with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    ('hello', 'hallo'),\n",
    "    ('hell', 'hallo'),\n",
    "    ('hel', 'hallo'),\n",
    "    ('helloo', 'hallo'),\n",
    "    ('hellooo', 'hallo'),\n",
    "    ('helo', 'hallo'),\n",
    "    ('heloo', 'hallo'),\n",
    "    ('helooo', 'hallo'),\n",
    "    ('allo', 'hallo'),\n",
    "    ('elo', 'hallo'),\n",
    "]\n",
    "\n",
    "import tensorflow as tf\n",
    "from rnn_utils import *\n",
    "\n",
    "print('hypothesis'.ljust(15) + 'truth'.ljust(15) + 'ler'.ljust(10))\n",
    "print('-'.join('' for _ in range(40)))\n",
    "for hypothesis, truth in samples:\n",
    "    h_values = encode(hypothesis)\n",
    "    h_indices = [[0, i] for i in range(len(h_values))]\n",
    "    h_shape = [1, len(h_values)]\n",
    "    h_tensor = tf.SparseTensor(indices=h_indices, values=h_values, dense_shape=h_shape)\n",
    "    \n",
    "    t_values = encode(truth)\n",
    "    t_indices = [[0, i] for i in range(len(t_values))]\n",
    "    t_shape = [1, len(h_values)]\n",
    "    t_tensor = tf.SparseTensor(indices=t_indices, values=t_values, dense_shape=t_shape)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        ler = tf.edit_distance(h_tensor, t_tensor)\n",
    "        edit_distance = sess.run(ler)\n",
    "        print(f'{hypothesis.ljust(15)}{truth.ljust(15)}{str(edit_distance[0]).ljust(10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of Concept\n",
    "\n",
    "The RNN is supposed to learn the relationship between an audio signal and its transcription, i.e. if trained properly it should be able to generate a transcription for any unseen audio signal afterwards. To see whether the RNN learns something useful we train the RNN on only a single corpus entry. For simplicity, only speech segments that do not contain numbers are considered. \n",
    "\n",
    "To get an intuition for how much the RNN is sensitive to different properties of the input data we examine the last two aspects a bit closer. To do this we use two corpus entries in different languages, whereas the average sequence length in one corpus is considerably longer than in the other. To minimize the influence of the pitch only corpus entries with female speakers were considered. For the sake of simplicity it is assumed that the speaking rate between the samples is similar. In consequence the term _length_ refers to both the length of the audio segment (in seconds) as well as the transcript length (number of characters).\n",
    "\n",
    "This leaves us with the RNN being trained in three variations:\n",
    "\n",
    "* **PoC #1**: Train on a corpus entry in German\n",
    "* **PoC #2**: Train on a corpus entry in English with an average segment length similar to the sample used for PoC #1\n",
    "* **PoC #3**: Train on a corpus entry in English with an average segment length that is longer than in the sample used for PoC #2\n",
    "\n",
    "By comparing PoC #1 and #2 we get a feeling for how much the training depends on the language of the corpus entries. By comparing PoC #2 and #3 we get a feeling for how much the training depends on the length of the speech segments. \n",
    "\n",
    "### PoC #1: German sample (short segments)\n",
    "For the _ReadyLingua_ corpus the first corpus entry in German is the poem _\"An die Freude\"_ from F. Schiller. For the first PoC we will train the RNN exclusively on this sample.\n",
    "\n",
    "#### Partial sample\n",
    "\n",
    "To get a fast feedback on the learning progress we will train the RNN only on the first five speech segments of the training sample. These segments have the following transcript (normalized):\n",
    "\n",
    "    1. an die freude von friedrich schiller\n",
    "    2. freude schoner gotterfunken\n",
    "    3. tochter aus elysium\n",
    "    4. wir betreten feuertrunken himmlische dein heiligtum\n",
    "    5. deine zauber binden wieder\n",
    "    \n",
    "We can now train the RNN with just these segments using the CTC- and LER-cost explained above. We train on 300 variants of the segments. In each variant the audio signal of the segment is cropped by a random value between 1 and 2000 frames. With a sampling rate of 16kHz this corresponds to an audio segment of 125ms at max. By comparing the actual transcription (_ground truth_) with the decoded output of the RNN (_prediction_) we can see that the RNN is indeed learning how to recognize speech.\n",
    "\n",
    "We can see that while in the beginning the generated transcript does not make much sense. It consists mainly of the letter `e` which happens to be the most frequent character in a German text. With proceeding training the generated transcript become clearer until they match up almost perfectly with the actual transcripts. This is also reflected in the curves for the CTC- and LER-cost:\n",
    "\n",
    "    Iteration 4:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       e ee e e e e\n",
    "    \n",
    "    Iteration 26:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       ie enienuenienheieiu\n",
    "    \n",
    "    Iteration 112:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       i betreterteueruner himmlische en heitum\n",
    "    \n",
    "    Iteration 178:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       wi betreteneuertrunkeni himmlische dein heiligtum\n",
    "\n",
    "    Iteration 298:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       wir betreten feuertrunken himmlische dein heigtum\n",
    "\n",
    "<img src=\"../assets/cost_ctc_sample.png\" alt=\"CTC cost\" style=\"width: 450px; float: left;\"/>\n",
    "<img src=\"../assets/cost_ler_sample.png\" alt=\"LER cost\" style=\"width: 450px;\"/>\n",
    "\n",
    "Of course by re-using the same sample 300 times the RNN has hopelessly overfitted to that sample. The RNN will not generalize well, meaning it is not expected to perform well on unseen examples. The result is therefore not representative. However, the PoC shows that the RNN is generally able to learn something useful.\n",
    "\n",
    "#### Whole sample\n",
    "\n",
    "To get a better intuition on how fast the RNN learns the relationship we train it on the same corpus entry, but this time we use all speech segments. We can see that the RNN still learns the relationships between audio signal and transcription, but requires a considerably larger number of training epochs to get comparable results (i.e. similar costs like when only training on five speech segments):\n",
    "\n",
    "    tbd.    \n",
    "\n",
    "### PoC #2: English sample (short segments)\n",
    "\n",
    "For the second PoC we use a corpus entry with similar properties like in PoC #1. The first corpus entry in the _ReadyLingua_ corpus is ... . Its first five speech segments have the following transcripts:\n",
    "\n",
    "    tbd...\n",
    "    \n",
    "Training the RNN the same way like shown above gives us the following progress:\n",
    "\n",
    "    tbd...\n",
    "    \n",
    "\n",
    "### PoC #: English sample (long segments)\n",
    "\n",
    "For the third PoC the chapter _\"Tom, the Piper's Son\"_ from _\"Mother Goose in Prose\"_ from the _LibriSpeech_-corpus was used (`corpus_entry.id=121669`). The first five speech segments are:\n",
    "\n",
    "    1. tom the pipers son\n",
    "    2. the pig was eat and tom was beat and tom ran crying down the street\n",
    "    3. he never did any work except to play the pipes and he played so badly that few pennies ever found their way into his pouch it was whispered around that old barney was not very honest\n",
    "    4. but he was so sly and cautious that no one had ever caught him in the act of stealing although a good many things had been missed after they had fallen into the old mans way barney had one son named tom\n",
    "    5. and they lived all alone in a little hut away at the end of the village street for toms mother had died when he was a baby you may not suppose that tom was a very good boy since he had such a queer father but neither was he very bad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the performance\n",
    "To compare the transcription produced by the RNN with the actual transcription we need a way to measure the similarity between these two texts. One way of doing this is the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) which calculates the degree of similarity as the edit distance (number of single-character edits required to change text 1 into text 2), whereas a lower value means a higher degree of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
