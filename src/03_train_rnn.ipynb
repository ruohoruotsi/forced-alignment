{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 3: Train an RNN\n",
    "\n",
    "From the previous steps we have corpora containing corpus entries with the following contents:\n",
    "\n",
    "1. audio data sampled to 16kHz (mono)\n",
    "2. segmentation of the audio into speech- and pause-segments detected by WebRTC\n",
    "3. segmentation of the audio into speech- and pause-segments derived from the raw data\n",
    "4. transcriptions for the raw speech segments in original and normalized form\n",
    "5. spectrograms of the audio to use as training data\n",
    "6. labels for the spectrogram-frames ot use as training labels\n",
    "\n",
    "We can now train an RNN that will learn the relationship between an audio signal and its textual representation using the [CTC loss function](https://www.cs.toronto.edu/~graves/icml_2006.pdf). \n",
    "\n",
    "The raw speech segments (3.) and their transcriptions (4.) are called the _labelled data_. This data consists of the input data  `X` and the labels `Y`. To train the network we use only a part of this labelled data. This part is referred to as **training set**. To prevent overfitting on this set we use another part of the labelled data to form a **validation/dev set**.\n",
    "\n",
    "If the training is successful, the RNN will be able to output a transcription for unknown instances that is roughly equivalent to the actual transcription. We can evaluate the RNN's performance by comparing its output with the actual transcription on a **test-set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = r'E:/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's do the imports and some helper functions before we start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from corpus_util import *\n",
    "from audio_util import *\n",
    "from data_util import *\n",
    "\n",
    "rl_corpus_root = os.path.join(corpus_root, 'readylingua-corpus')\n",
    "ls_corpus_root = os.path.join(corpus_root, 'librispeech-corpus')\n",
    "\n",
    "rl_corpus_path = os.path.join(rl_corpus_root, 'readylingua.corpus')\n",
    "ls_corpus_path = os.path.join(ls_corpus_root, 'librispeech.corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pronunciation of a given piece of text is highly dependent on the language, we train the RNN only on a specific language of the corpus. Therefore, let's load the corpus and extract the entries in German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_corpus_de = load_corpus(rl_corpus_path)(languages='de')\n",
    "rl_corpus_de.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the transcript\n",
    "\n",
    "In order to limit the number of target classes to the characters of the alphabet we need to normalize the transcripts. Normalizing involves the following steps:\n",
    "\n",
    "1. remove leading and trailing whitespaces (trimming)\n",
    "2. remove multiple subsequent occurences of whitespace within the transcript\n",
    "3. replacing accentuated characters with character from the alphabet (e.g. _é_/_è_/_ê_/...->e, _ß_->ss, etc...)\n",
    "4. removing non-alphanumeric characters (removes punctuation)\n",
    "5. make everything lowercase\n",
    "\n",
    "You can edit/execute the cell below with your own examples to see the result of normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string_utils import *\n",
    "samples = [ 'Crème-brûlée', 'Außerirdische', ' foo    bar   ']\n",
    "for sample in samples:\n",
    "    print(f'{sample} ==> {normalize(sample)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the transcript\n",
    "\n",
    "In order to use the transcripts as training labels, it needs to be tokenized first. By tokenizing we mean splitting the transcription into words and then into characters. The tokens are the characters of the transcription, whereas a special token `<space>` is used between the characters of two words.\n",
    "\n",
    "The mapping of audio to text is actually a classification problem: Parts of the audio signal are mapped each to a specific character (i.e. _token_). Since RNN resp. TensorFlow work best with numeric data, we need to encode the tokens to put them on an ordinal scale. The following table shows how the encoding is done:\n",
    "\n",
    "| **Token**    | `<space>` | `a` | `b` | `c` | ... | `z`  |\n",
    "|--------------|:---------:|:---:|:---:|:---:|:---:|:----:|\n",
    "| **Encoding** | `0`       | `1` | `2` | `3` | ... | `26` |\n",
    "\n",
    "The following table shows how a transcript is converted to its encoded form:\n",
    "\n",
    "| **Original transcript** | The quick, brown fox jumps over the lazy dog!  |\n",
    "|-------------------------|------------------------------------------------|\n",
    "| **Normalized transcript** | the quick brown fox jumps over the lazy dog |\n",
    "| **Tokenized transcript** | `['t', 'h', 'e', '<space>, 'q', 'u', 'i', 'c', 'k', '<space>', 'b', 'r', 'o', 'w', 'n', ...]` |\n",
    "| **Encoded transcript** | `[ 20, 8, 5, 0, 17, 21, 9, 3, 11, 0, 2, 18, 15, 23, 14]` |\n",
    "\n",
    "## The issue with numbers\n",
    "\n",
    "Numbers in transcript pose a special problem, since their pronunciation differs fundamentally from their textual representation, if written with digits (which is usually the case). Consider the number `8`, which is represented textually by the digit `'8'` and is pronounced as `eight`. In this case, the actual sequence of characters (`'e', 'i', 'g', 'h', 't')` is replaced by a single character `'8'` and can therefore not be approximated like ordinary words.\n",
    "\n",
    "The problem becomes even harder since compound number are sometimes pronounced differently than their individual parts would be pronounced. Consider the number `13` which is pronounced `'thirteen'` (and not `'onethree'`!). This becomes especially important in languages like German which swap the decimal part (e.g. `'21'` is pronounced as `'one-and-twenty'`).\n",
    "\n",
    "Since numbers are a problem of their own we want to limit their influence on the training process by training the RNN only on transcripts without numbers. We can filter those out by using the corpus entry as a function and pass in the `numeric=False` argument to get only those speech segments whose transcripts do not contain numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = rl_corpus_de['edznachrichten180111']\n",
    "corpus_entry.summary()\n",
    "\n",
    "corpus_entry_nonnumeric = corpus_entry(numeric=False)\n",
    "corpus_entry_nonnumeric.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN architecture\n",
    "\n",
    "We train an RNN with the following architecture (inspired by [this repository](https://github.com/philipperemy/tensorflow-ctc-speech-recognition)):\n",
    "\n",
    "* number of features: 13\n",
    "* number of hidden layers: 1\n",
    "* RNN-cell type: LSTM\n",
    "\n",
    "### RNN cost\n",
    "We measure the cost in two ways:\n",
    "\n",
    "* CTC-cost\n",
    "* Label Error Rate (LER)\n",
    "\n",
    "#### CTC cost\n",
    "The CTC cost is calculated as follows:\n",
    "\n",
    "tbd...\n",
    "\n",
    "#### Label Error Rate (LER)\n",
    "The LER is defined as the [edit distance](https://www.tensorflow.org/api_docs/python/tf/edit_distance) between prediction (_hypothesis_) and actual labels (_truth_), also called the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance). Observe for example the LER for the hypothesis `hello` and the truth `hallo`: The two strings differ in 1 of 5 characters, therefore the LER is `0.2`.\n",
    "\n",
    "The LER can also be computed for strings of different lengths. The following table gives an overview of a few samples.\n",
    "\n",
    "| Hypothesis | Truth | LER |\n",
    "|---|---|---|\n",
    "| 'hello' | 'hallo' | 0.2\n",
    "| 'hell' | 'hallo' | 0.4\n",
    "| 'hel' | 'hallo' | 0.6\n",
    "| 'helloo' | 'hallo' | 0.4\n",
    "| 'hellooo' | 'hallo' | 0.6\n",
    "| 'helo' | 'hallo' | 0.4\n",
    "| 'heloo' | 'hallo' | 0.4\n",
    "| 'helooo' | 'hallo' | 0.6\n",
    "| 'allo' | 'hallo' | 0.2\n",
    "| 'elo' | 'hallo' | 0.6\n",
    "\n",
    "You can also execute the cell below to see how the values are calculated with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    ('hello', 'hallo'),\n",
    "    ('hell', 'hallo'),\n",
    "    ('hel', 'hallo'),\n",
    "    ('helloo', 'hallo'),\n",
    "    ('hellooo', 'hallo'),\n",
    "    ('helo', 'hallo'),\n",
    "    ('heloo', 'hallo'),\n",
    "    ('helooo', 'hallo'),\n",
    "    ('allo', 'hallo'),\n",
    "    ('elo', 'hallo'),\n",
    "]\n",
    "\n",
    "import tensorflow as tf\n",
    "from rnn_utils import *\n",
    "\n",
    "print('hypothesis'.ljust(15) + 'truth'.ljust(15) + 'ler'.ljust(10))\n",
    "print('-'.join('' for _ in range(40)))\n",
    "for hypothesis, truth in samples:\n",
    "    h_values = encode(hypothesis)\n",
    "    h_indices = [[0, i] for i in range(len(h_values))]\n",
    "    h_shape = [1, len(h_values)]\n",
    "    h_tensor = tf.SparseTensor(indices=h_indices, values=h_values, dense_shape=h_shape)\n",
    "    \n",
    "    t_values = encode(truth)\n",
    "    t_indices = [[0, i] for i in range(len(t_values))]\n",
    "    t_shape = [1, len(h_values)]\n",
    "    t_tensor = tf.SparseTensor(indices=t_indices, values=t_values, dense_shape=t_shape)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        ler = tf.edit_distance(h_tensor, t_tensor)\n",
    "        edit_distance = sess.run(ler)\n",
    "        print(f'{hypothesis.ljust(15)}{truth.ljust(15)}{str(edit_distance[0]).ljust(10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of Concept\n",
    "\n",
    "The RNN is supposed to learn the relationship between an audio signal and its transcription, i.e. if trained properly it should be able to generate a transcription for any unseen audio signal afterwards. To see whether the RNN learns something useful we train the RNN on only a single corpus entry from which we only use the first five speech segments. For simplicity, only speech segments that do not contain numbers are considered.\n",
    "\n",
    "For the _ReadyLingua_ corpus the first corpus entry is the poem _\"An die Freude\"_ from F. Schiller. Its first five segments have the following transcript (normalized):\n",
    "\n",
    "    an die freude von friedrich schiller\n",
    "    freude schoner gotterfunken\n",
    "    tochter aus elysium\n",
    "    wir betreten feuertrunken himmlische dein heiligtum\n",
    "    deine zauber binden wieder\n",
    "    \n",
    "We can now train the RNN with just these segments using the CTC- and LER-cost explained above. We train on 300 variants of the segments. In each variant the audio signal of the segment is cropped by 2000 frames (with a sampling rate of 16kHz this corresponds to 125ms). By comparing the actual transcription (_ground truth_) with the decoded output of the RNN (_prediction_) we can see that the RNN is indeed learning how to recognize speech.\n",
    "\n",
    "\n",
    "We can see that while in the beginning the generated transcript does not make much sense. It consists mainly of the letter `e` which happens to be the most frequent character in a German text. With proceeding training the generated transcript become clearer until they match up almost perfectly with the actual transcripts. This is also reflected in the curves for the CTC- and LER-cost:\n",
    "\n",
    "    Iteration 4:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       e ee e e e e\n",
    "    \n",
    "    Iteration 26:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       ie enienuenienheieiu\n",
    "    \n",
    "    Iteration 112:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       i betreterteueruner himmlische en heitum\n",
    "    \n",
    "    Iteration 178:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       wi betreteneuertrunkeni himmlische dein heiligtum\n",
    "\n",
    "    Iteration 298:\n",
    "    Ground truth (train-set):     wir betreten feuertrunken himmlische dein heiligtum\n",
    "    Prediction (train-set):       wir betreten feuertrunken himmlische dein heigtum\n",
    "\n",
    "<img src=\"./assets/cost_ctc_sample.png\" alt=\"CTC cost\" style=\"width: 450px; float: left;\"/>\n",
    "<img src=\"./assets/cost_ler_sample.png\" alt=\"LER cost\" style=\"width: 450px;\"/>\n",
    "\n",
    "Of course by re-using the same sample 300 times the RNN has hopelessly overfitted to that sample. The RNN will not generalize well, meaning it will not perform well on unseen examples. The result is not representative. However, the PoC shows that the RNN is generally able to learn something useful given enough data to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the performance\n",
    "To compare the transcription produced by the RNN with the actual transcription we need a way to measure the similarity between these two texts. One way of doing this is the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) which calculates the degree of similarity as the edit distance (number of single-character edits required to change text 1 into text 2), whereas a lower value means a higher degree of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
