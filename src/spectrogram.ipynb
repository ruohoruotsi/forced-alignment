{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "from IPython.display import HTML, Audio\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from util.corpus_util import *\n",
    "from util.audio_util import *\n",
    "\n",
    "rl_corpus_root = r'E:\\readylingua-corpus'\n",
    "\n",
    "rl_corpus = load_corpus(rl_corpus_root)\n",
    "\n",
    "def show_labelled_data(corpus_entry):\n",
    "    rate, audio = corpus_entry.rate, corpus_entry.audio\n",
    "    print(f'rate: = {rate}')\n",
    "    print(f'audio.shape: {audio.shape}')\n",
    "    print(f'len(audio): {len(audio)}')\n",
    "    \n",
    "    display(Audio(data=audio, rate=rate))\n",
    "    \n",
    "    freqs, times, spec = load_x(corpus_entry, rl_data_root)\n",
    "    y = load_y(corpus_entry, rl_data_root)\n",
    "    print(f'freqs.shape: {freqs.shape}')\n",
    "    print(f'times.shape: {times.shape}')\n",
    "    print(f'spec.shape: {spec.shape}')\n",
    "    print(f'y.shape: {y.shape}')\n",
    "    \n",
    "    freqs, times, spectrogram = log_specgram(audio, rate)\n",
    "    print(f'freqs.shape: {freqs.shape}')\n",
    "    print(f'times.shape: {times.shape}')\n",
    "    print(f'spectrogram.shape: {spectrogram.shape}')\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax_wave = show_wave(corpus_entry, fig)\n",
    "    \n",
    "    ax_spec, extent = show_spectrogram(freqs, times, spec, fig)\n",
    "\n",
    "    left, right, bottom, top = extent\n",
    "    boundaries = calculate_pause_boundaries(y)\n",
    "    show_pause_segments(ax_wave, boundaries, len(audio))\n",
    "    show_pause_segments(ax_spec, boundaries, right-left)\n",
    "    \n",
    "def show_wave(corpus_entry, fig=None):\n",
    "    rate, audio = corpus_entry.audio\n",
    "    \n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.set_title('Raw wave of ' + corpus_entry.audio_file)\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.plot(np.linspace(0, len(audio), len(audio)), audio)\n",
    "    return ax1\n",
    "\n",
    "def show_wave_old(audio, sample_rate, ax=None, title=None):\n",
    "    if not ax:\n",
    "        plt.figure(figsize=default_figsize, facecolor=default_facecolor)\n",
    "        ax = plt.axes()\n",
    "        \n",
    "    ax.set_xlim(0, len(audio))\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "        \n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_xlabel('Audio frames')\n",
    "    ax.plot(np.linspace(0, len(audio), len(audio)), audio)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def show_spectrogram(freqs, times, spec, fig=None):\n",
    "    if not fig:\n",
    "        fig = plt.figure()\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    \n",
    "    extent = [times.min(), times.max(), freqs.min(), freqs.max()]\n",
    "    \n",
    "    print(f'spec.shape = (f, T_x) = {spec.shape}')\n",
    "    im = plt.imshow(spec, aspect='auto', origin='lower', extent=extent)\n",
    "    \n",
    "    ax = im.axes\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax.set_xlim(times.min(), times.max())\n",
    "    ax.set_yticks(freqs[::16])\n",
    "    ax.set_xticks(times[::int(len(times)/10)])\n",
    "    \n",
    "    ax.set_xlabel('Seconds')\n",
    "    ax.set_ylabel('Freqs in Hz')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return im.axes, extent  \n",
    "\n",
    "def show_pause_segments(ax, boundaries, x_width):\n",
    "    for pause_start, pause_end in boundaries:\n",
    "        ax.axvspan(pause_start*x_width, pause_end*x_width, color='red', alpha=0.5)\n",
    "    \n",
    "def calculate_pause_boundaries(y):\n",
    "    boundaries = np.flatnonzero(np.diff(np.r_[0,y,0]) != 0).reshape(-1,2) - [0,1]\n",
    "    return [tuple(elem) for elem in boundaries / len(y)]\n",
    "\n",
    "def calculate_pause_boundaries_from_ground_truth(corpus_entry):\n",
    "    \"\"\"calculates the boundaries of pause segments in x given a label vector y.\n",
    "\n",
    "    :y: numpy array of shape (1, T_y) containing the labels (\"speech\"/\"no speech\") for a RNN\n",
    "    :x: numpy array of shape (T_x, ) containing the audio signal for a RNN\n",
    "    \"\"\"\n",
    "\n",
    "    x = corpus_entry.audio\n",
    "    y = corpus_entry.labels\n",
    "\n",
    "    num_x = len(x)\n",
    "\n",
    "    # pause boundaries as binary vector: [0,0,1,1,1,0,...]\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    # pause boundaries as indices of 1-groups in y (start and end indices of group): [[2,4], ...]\n",
    "    boundaries = np.flatnonzero(np.diff(np.r_[0,y,0]) != 0).reshape(-1,2) - [0,1]\n",
    "\n",
    "    # pause boundaries as indices of 1-groups in x (calculated from relative position of frames in y)\n",
    "    boundaries = len(x) * boundaries / len(y)\n",
    "\n",
    "    # no fractional indices\n",
    "    return boundaries.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize directly from audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = rl_corpus[0]\n",
    "# corpus_entry = random.choice(rl_corpus)\n",
    "print(f'corpus_entry.id: {corpus_entry.id}')\n",
    "print(f'corpus_entry.name: {corpus_entry.name}')\n",
    "\n",
    "show_labelled_data(corpus_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
