{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Corpus creation\n",
    "This IPython notebook documents the creation of the corpora from raw data. The corpora can also be created interactively.\n",
    "\n",
    "## Background\n",
    "\n",
    "Machine Learning task in the field of _Natural Language Processing (NLP)_ often rely on corpora. The ASR-stage in this project is no exception. Raw data is available from manifold sources. For this project, two sources (_ReadyLingua_ and _LibriSpeech_) were considered. However, other sources are conceivable. The final solution should be able to train on data from arbitrary resources. However, since properties and format of the raw data is usually not standardized between sources, some pre-processing is required in order to bring raw data into a format that can be used by the ASR stage.\n",
    "\n",
    "Since each data source makes its own assumptions about how data should be represented, a separate preprocessing step is required for each data source. The processed data is then stored in _corpora_, which contain the actual data (audio signals and transcripts) as well as metadata (audio segmentation information, audio length, sampling rate, language, speaker gender, etc...). The data from the sources used in this project comes from different distributions (e.g. number of languages, speaker per gender, etc.). Therefore the processed data has been stored in different corpora.\n",
    "\n",
    "## Prerequisites\n",
    "This project was built using Python 3.6 and Anaconda 3. Please install the packages listed in `requirements.txt`. Additionally, you need the following tools and resources:\n",
    "\n",
    "* [FFMPEG](http://www.ffmpeg.org/): for the conversion and/or resampling of audio files\n",
    "* _ReadyLingua_ raw data: The aligned data from _ReadyLingua_ is not public domain. You need to get permission of the owner and store them on your machine.\n",
    "\n",
    "All other data is publicly available and will be downloaded as needed by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source directory\n",
    "Since data from ReadyLingua and PodClub is not open to the public you must specify the path to the directory where those files are stored in the following cell. You must use an absolute path.\n",
    "\n",
    "Data from the LibriSpeech is available under the [Creative Commons](https://en.wikipedia.org/wiki/Creative_Commons) license. You can download the files yourself and specify an absolute path to folder where the files are stored. If the directory is empty, LibriSpeech data will automatically be downloaded and extracted there. If the directory is not empty, it is assumed that the data from LibriSpeech was already manually downloaded and extracted in this directory. In this case the directory structure must match the expected structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_source_root = r'D:\\corpus\\readylingua-raw'   # path to directory where raw ReadyLingua data is stored\n",
    "ls_source_root = r'D:\\corpus\\librispeech-raw'   # path to directory where LibriSpeech files are or will be downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target directory\n",
    "This notebook will create various corpora that need to be persisted somewhere. Specify the path to a directory that provides enough storage. Approximately 350GB of free storage is required. Note: Final storage use might be lower since some of the memory is only used temporarily.\n",
    "\n",
    "**Don't forget to execute the cell to apply the changes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_root = r'E:/'                            # path to the directory where the corpora will be created (must have at least 350GB of free storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions\n",
    "Execute the cell below to import modules and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports and some helper functions. You don't need to change anything in here!\n",
    "\"\"\"\n",
    "import tarfile\n",
    "import random\n",
    "from os import listdir, rmdir, remove, makedirs\n",
    "from random import randint\n",
    "from shutil import move\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import create_ls_corpus\n",
    "import create_rl_corpus\n",
    "from util.audio_util import *\n",
    "from util.corpus_util import *\n",
    "from IPython.display import HTML, Audio\n",
    "import ipywidgets as widgets\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# path to target directory for ReadyLingua corpus files (default value)\n",
    "rl_target_root = os.path.join(target_root, 'readylingua-corpus')\n",
    "# path to target directory for LibriSpeech corpus files (default value)\n",
    "ls_target_root = os.path.join(target_root, 'librispeech-corpus')\n",
    "\n",
    "def show_corpus_entry(corpus_entry, speech=None, speech_unaligned=None, pause=None):\n",
    "    speech = speech if speech else random.choice(corpus_entry.speech_segments)\n",
    "    speech_unaligned = speech_unaligned if speech_unaligned \\\n",
    "                        else random.choice(corpus_entry.speech_segments_unaligned) if corpus_entry.speech_segments_unaligned \\\n",
    "                        else None\n",
    "    pause = pause if pause else random.choice(corpus_entry.pause_segments)\n",
    "\n",
    "    show_audio(corpus_entry)\n",
    "    show_segment(speech)\n",
    "    if speech_unaligned:\n",
    "        show_segment(speech_unaligned)\n",
    "    show_segment(pause)\n",
    "\n",
    "\n",
    "def show_audio(corpus_entry):\n",
    "    title = HTML(f\"\"\"\n",
    "    <h3>Sample corpus entry: {corpus_entry.name}</h3>\n",
    "    <p><strong>Path to raw data</strong>: {corpus_entry.raw_path}</p>\n",
    "    <p>{len(corpus_entry.speech_segments)} speech segments, {len(corpus_entry.pause_segments)} pause segments</p>\n",
    "    \"\"\")\n",
    "    audio = Audio(data=corpus_entry.audio, rate=corpus_entry.rate)\n",
    "    transcript = widgets.Accordion(children=[widgets.HTML(f'<pre>{corpus_entry.transcript}</pre>')], selected_index=None)\n",
    "    transcript.set_title(0, 'Transcript')\n",
    "    \n",
    "    display(title)\n",
    "    display(audio)\n",
    "    display(transcript)\n",
    "    \n",
    "def show_segment(segment):\n",
    "    title = HTML(f'<strong>Sample {segment.segment_type}</strong> (start_frame={segment.start_frame}, end_frame={segment.end_frame})')\n",
    "    audio = Audio(data=segment.audio, rate=segment.rate)\n",
    "\n",
    "    display(title)\n",
    "    display(audio)\n",
    "    if segment.text:\n",
    "        transcript = HTML(f'<pre>{segment.transcript}</pre>')\n",
    "        display(transcript)\n",
    "\n",
    "\n",
    "def download_file(url, target_dir):\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length', 0));\n",
    "    block_size = 1024\n",
    "    wrote = 0\n",
    "    tmp_file = os.path.join(target_dir, 'download.tmp')\n",
    "    if not exists(target_dir):\n",
    "        makedirs(target_dir)\n",
    "\n",
    "    with open(tmp_file, 'wb') as f:\n",
    "        with tqdm(r.iter_content(32 * block_size), total=total_size, unit='B', unit_divisor=block_size,\n",
    "                  unit_scale=True) as pbar:\n",
    "            for data in r.iter_content(32 * 1024):\n",
    "                wrote = wrote + len(data)\n",
    "                f.write(data)\n",
    "                pbar.update(len(data))\n",
    "\n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "\n",
    "    print('Extracting data...')\n",
    "    tar = tarfile.open(tmp_file, \"r:gz\")\n",
    "    tar.extractall(target_dir)\n",
    "    tar.close()\n",
    "\n",
    "    remove(tmp_file)\n",
    "\n",
    "\n",
    "def move_files(src_dir, target_dir):\n",
    "    for filename in listdir(src_dir):\n",
    "        move(os.path.join(src_dir, filename), os.path.join(target_dir, filename))\n",
    "    rmdir(src_dir)\n",
    "\n",
    "\n",
    "def on_download_ls_button_click(sender):\n",
    "    global ls_source_root\n",
    "    print('Downloading LibriSpeech data... Get lunch or something!')\n",
    "    print('Download 1/2: Audio data')\n",
    "    download_dir = os.path.join(ls_source_root, 'audio')\n",
    "    if exists(download_dir) and listdir(download_dir):\n",
    "        print(f'Directory {download_dir} exists and is not empty. Assuming data was already downloaded there.')\n",
    "    else:\n",
    "        download_file('http://www.openslr.org/resources/12/original-mp3.tar.gz', download_dir)\n",
    "        print('Done! Moving files...')\n",
    "        move_files(os.path.join(download_dir, 'LibriSpeech'), download_dir)\n",
    "\n",
    "    print('Download 2/2: Text data')\n",
    "    download_dir = os.path.join(ls_source_root, 'books')\n",
    "    if exists(download_dir) and listdir(download_dir):\n",
    "        print(f'Directory {download_dir} exists and is not empty. Assuming data was already downloaded there.')\n",
    "    else:\n",
    "        download_file('http://www.openslr.org/resources/12/original-books.tar.gz', download_dir)\n",
    "        move_files(os.path.join(download_dir, 'LibriSpeech'), download_dir)\n",
    "        makedirs(os.path.join(download_dir, 'utf-8'))\n",
    "        move_files(os.path.join(download_dir, 'books', 'utf-8'), os.path.join(download_dir, 'utf-8'))\n",
    "        move_files(os.path.join(download_dir, 'books', 'ascii'), os.path.join(download_dir, 'ascii'))\n",
    "        delete_directory = os.path.join(download_dir, 'books')\n",
    "        print(f'Done! Please delete {delete_directory} manually (not needed)')\n",
    "\n",
    "    print(f'Files downloaded and extracted to: {ls_source_root}')\n",
    "\n",
    "\n",
    "def on_create_rl_button_click(sender):\n",
    "    global rl_corpus_file\n",
    "    print('Creating ReadyLingua corpus... Get a coffee or something!')\n",
    "    rl_corpus, rl_corpus_file = create_rl_corpus.create_corpus(source_root=rl_source_root, target_root=rl_target_root)\n",
    "    print(f'Done! Corpus with {len(rl_corpus)} entries saved to {rl_corpus_file}')\n",
    "\n",
    "\n",
    "def on_create_ls_button_click(sender):\n",
    "    global ls_corpus_file\n",
    "    print('Creating LibriSpeech corpus... Go to bed or something!')\n",
    "    ls_corpus, ls_corpus_file = create_ls_corpus.create_corpus(source_root=ls_source_root, target_root=ls_target_root)\n",
    "    print(f'Done! Corpus with {len(ls_corpus)} entries saved to {rl_corpus_file}')\n",
    "\n",
    "# UI elements\n",
    "layout = widgets.Layout(width='250px', height='50px')\n",
    "download_ls_button = widgets.Button(description=\"Download LibriSpeech Data\", button_style='info', layout=layout, icon='download')\n",
    "download_ls_button.on_click(on_download_ls_button_click)\n",
    "create_rl_button = widgets.Button(description=\"Create ReadyLingua Corpus\", button_style='warning', layout=layout, icon=\"book\", tooltip='~5 minutes')\n",
    "create_rl_button.on_click(on_create_rl_button_click)\n",
    "create_ls_button = widgets.Button(description=\"Create LibriSpeech Corpus\", button_style='warning', layout=layout,icon=\"book\", tooltip='~5 hours')\n",
    "create_ls_button.on_click(on_create_ls_button_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Corpus structure\n",
    "The alignment information is extracted from the raw data and stored as a **corpus** containing **corpus entries**. A corpus entry reflects a single instance for training, validation or evaluation. It contains all the information about the audio and its segmentation. It therefore contains information about **segments**, which are either speech segments, pause segments or unaligned speech segments. Unaligned speech segments are parts of the audio signal which are known to contain speech but for which no metadata from manual segmentation is available. They may therefore contain speech or pause segments themselves and could be further subdivided.\n",
    "\n",
    "The following figure shows an illustration of the most important classes used for corpus creation:\n",
    "\n",
    "![class diagram](../assets/class_diagram.png)\n",
    "\n",
    "### Preprocessing\n",
    "The raw data was integrated as-is applying only the following preprocessing steps:\n",
    "\n",
    "* **Resampling**: Audio data was resampled to 16kHz (mono) WAV files\n",
    "* **Cropping**: Some of the audio files (especially in the LibriSpeech data contained some preliminary information about LibriVox and the book being read before the actual recording. This speech data was not aligned. The audio was therefore cropped at the beginning to the frame where the first alignment information (speech or pause segments) begins. Likewise, the audio is cropped at the end to the frame where the last alignment information ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus entries\n",
    "In order to allow data from all sources for training, it had to be converted to a common format. Since (to my knowledge) there is not a standardized format for FA, I had to define one myself. Therefore I went for the following structure for a single corpus entry:\n",
    "\n",
    "```JSON\n",
    "// corpus is iterable over its corpus_entries\n",
    "Corpus = {\n",
    "    'name': string,                    // display name\n",
    "    'root_path': string,               // absolute path to the directory containing the corpus files\n",
    "    'corpus_entries': [CorpusEntry]    // the entries of the corpus\n",
    "}\n",
    "\n",
    "// corpus_entry is iterableover its segments\n",
    "CorpusEntry = \n",
    "{\n",
    "    'corpus': Corpus,                  // reference to the corpus\n",
    "    'audio_file': string               // absolute path to the preprocessed audio file\n",
    "    'transcript': string,              // transcription of the audio as raw (unaligned) text   \n",
    "    'segments': [Segment],             // speech- and pause-segments of the audio\n",
    "    'original_path': string            // absolute path to the directory containing the raw files\n",
    "    'name': string                     // display name\n",
    "    'id': string                       // unique identifier\n",
    "    'language': string,                // 'de'/'fr'/'it'/'en'/'es'/'unknown'\n",
    "    'chapter_id': string,              // identifier of the chapter of the book if available, else 'unknown'\n",
    "    'speaker_id': string,              // identifier of the speaker if available, else 'unknown'\n",
    "    'original_sampling_rate': string,  // sampling rate of the raw audio file\n",
    "    'original_channels': string,       // number of channels in the raw audio file\n",
    "    'subset': string,                  // membership to a subset ('train'/'dev'/'test'/'unknown')\n",
    "    'media_info': dict,                // PyDub information about the converted audio file\n",
    "    'speech_segments': [Segment],      // segments filtered for type=='speech' (at runtime)\n",
    "    'pause_segments': [Segment],       // segments filtered for type=='pause' (at runtime)\n",
    "    'alignment': ([byte], [Segment]),  // audio and segmentation information\n",
    "    'alignment_cropped': ([byte], [Segment]) // audio and segmentation information with start and end cropped\n",
    "}\n",
    "\n",
    "// definition of a speech or pause segment\n",
    "Segment = \n",
    "{\n",
    "    'corpus_entry': CorpusEntry,       // reference to the corresponding CorpusEntry\n",
    "    'start_frame': int,                // index of the start frame of the segment within the audio\n",
    "    'end_frame': int,                  // index of the end frame of the segment  within the audio\n",
    "    'start_text': int,                 // index of first character of the segment in the transcription\n",
    "    'end_text': int,                   // index of the last character of the segment in the transcription\n",
    "    'segment_type': string,            // 'speech' for a speech segment, 'pause' for a pause segment\n",
    "    'audio': [byte],                   // part of the audio of the corpus entry which belongs to this segment\n",
    "    'text': string                     // part of the transcription of the corpus entry which belongs to this segment\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ReadyLingua Corpus\n",
    "ReadyLingua (RL) provides alignment data distributed over several files files:\n",
    "\n",
    "* `*.wav` or `*.mp3`: Audio file containing the speech\n",
    "* `*.txt`: UTF-8 encoded (unaligned) transcription\n",
    "* `* - Segmentation.xml`: file containing the definition of speech- and pause segments\n",
    "```XML\n",
    "<Segmentation>\n",
    "    <SelectionExtension>0</SelectionExtension>\n",
    "    <Segments>\n",
    "\t<Segment id=\"1\" start=\"83790\" end=\"122598\" class=\"Speech\" uid=\"5\" />\n",
    "\t...\n",
    "    </Segments>\n",
    "    <Segmenter SegmenterType=\"SICore.AudioSegmentation.EnergyThresholding\">\n",
    "        <MaxSpeechSegmentExtension>50</MaxSpeechSegmentExtension>\n",
    "        <Length>-1</Length>\n",
    "        <Energies>\n",
    "            <Value id=\"1\" value=\"0\" />\n",
    "            ...\n",
    "        </Energies>\n",
    "        <OriginalSegments>\n",
    "            <Segment id=\"1\" start=\"83790\" end=\"100548\" class=\"Speech\" uid=\"2\" />\n",
    "            ...\n",
    "        </OriginalSegments>\n",
    "        <EnergyPeak>3569753</EnergyPeak>\n",
    "        <StepSize>441</StepSize>\n",
    "        <ITL>146139</ITL>\n",
    "        <ITU>730695</ITU>\n",
    "        <LastUid>2048</LastUid>\n",
    "        <MinPauseDuration>200</MinPauseDuration>\n",
    "        <MinSpeechDuration>150</MinSpeechDuration>\n",
    "        <BeginOfSilence>1546255</BeginOfSilence>\n",
    "        <SilenceLength>100</SilenceLength>\n",
    "        <ThresholdCorrectionFactor>1</ThresholdCorrectionFactor>\n",
    "    </Segmenter>\n",
    "</Segmentation>\n",
    "```\n",
    "* `* - Index.xml`: file containing the actual alignments of text to audio\n",
    "```XML\n",
    "<XMLIndexFile>\n",
    "    <Version>2.0.0</Version>\n",
    "    <SamplingRate>44100</SamplingRate>\n",
    "    <NumberOfIndices>91</NumberOfIndices>\n",
    "    <TextAudioIndex>\n",
    "        <TextStartPos>0</TextStartPos>\n",
    "        <TextEndPos>36</TextEndPos>\n",
    "        <AudioStartPos>952101</AudioStartPos>\n",
    "        <AudioEndPos>1062000</AudioEndPos>\n",
    "        <SpeakerKey>-1</SpeakerKey>\n",
    "    </TextAudioIndex>\n",
    "    ...\n",
    "</XMLIndexFile>    \n",
    "```\n",
    "* `* - Project.xml`: Project file binding the different files together for a corpus entry (note: this file is optional, i.e. there may be not project file for a corpus entry)\n",
    "\n",
    "Corpus entries are organized in a folder hierarchy. There is a fileset for each corpus entry. Usually, the files for a specific corpus entry reside in a leaf directory (i.e. a directory without further subdirectories). If there is a project file, this file is used to locate the files needed.\n",
    "\n",
    "Audio data is provided as Wave-Files with a sampling rate of 44,1 kHz (stereo) or MP3 files. Because most ASR corpora provide their recordings as wave files with a sampling rate of 16 kHz the files were downsampled and the alignment information adjusted. The raw transcription is integrated as-is. The XML files are parsed to extract the alignment data. Alignment-, textual and downsampled audio data are merged into a corpus entry as described above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus entries\n",
    "We need to extract the alignments from the segmentation information of the raw data. For this, the downloaded data needs to be converted to corpus entries. This process takes a few minutes, so this is a good time to have a coffee break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_rl_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore corpus\n",
    "Let's load the newly created corpus (needs to be done only once) and print some stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_corpus = load_corpus(rl_target_root)\n",
    "rl_corpus.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access each corpus entry either by a numerical index or by its ID (string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acces by index\n",
    "first_entry = rl_corpus[0]\n",
    "first_entry.summary()\n",
    "\n",
    "# access by ID\n",
    "other_entry = rl_corpus['news170524']\n",
    "other_entry.summary()\n",
    "\n",
    "# get a list of IDs\n",
    "rl_corpus.keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter the corpus by language to get only the corpus entry with the specified language(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_corpus_de = rl_corpus(languages='de')\n",
    "rl_corpus_de.summary()\n",
    "\n",
    "rl_corpus_fr = rl_corpus(languages='fr')\n",
    "rl_corpus_fr.summary()\n",
    "\n",
    "rl_corpus_de_fr = rl_corpus(languages=['de', 'fr'])\n",
    "rl_corpus_de_fr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if everything worked as expected let's check out a sample alignment. You can execute the cell below to show a random alignment from a random corpus entry. You can execute the cell several times to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = random.choice(rl_corpus_de)\n",
    "# corpus_entry = rl_corpus['edznachrichten180201']\n",
    "show_corpus_entry(corpus_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LibriSpeech Corpus\n",
    "The _LibriSpeech_ raw data is split into training-, dev- and test-set (`train-*.tar.gz`, `dev-*.tar.gz` and `test-*.tar.gz`). However, those sets only contain the transcript as a set of segments and an audio file for each segment. They do not contain any temporal information which is needed for alignment.\n",
    "\n",
    "Luckily, there is also the `original-mp3-tar.gz` for download which contains the original LibriVox mp3 files (from which the corpus was created) along with the alignment information. Alignment is made on utterance-level, i.e. the transcript is split up into segments whereas each segment corresponds to an utterance. Segments were derived by allowing splitting on every silence interval longer than 300ms. \n",
    "\n",
    "The data is organized into subdirectories of the following path format:\n",
    "\n",
    "    ./LibriSpeech/mp3/{speaker_id}/{chapter_id}/\n",
    "\n",
    "There is one directory per entry containing all the information about a recording. For this project the following files are important:\n",
    "\n",
    "- **Audio recording** `{chapter_id}.mp3`: The audio file containing the recording. The audio is mono with a bitrate of 128 kB/s and a sampling rate of 44.1 kHz and needs to be converted/resampled to the target format.\n",
    "- **Transcription file** `{speaker_id}-{chapter_id}.trans.txt`: Text file containing the transcriptions of the segments (one segment per line). Each line is prefixed with the transcription ID. The transcription is all uppercase and does not contain any punctuation.\n",
    "```\n",
    "14-208_0000 CHAPTER ELEVEN THE MORROW BROUGHT A VERY SOBER LOOKING MORNING THE SUN MAKING ONLY A FEW EFFORTS...\n",
    "```\n",
    "- **Segmentation file** `{speaker_id}-{chapter_id}.seg.txt`: Text file containing temporal information about the segments (one segment per line). Each line is prefixed with the ID of the transcription for which the information is valid. The time is indicated in seconds. Example:\n",
    "```\n",
    "14-208_0000 25.16 40.51\n",
    "```\n",
    "\n",
    "In order to create the corpus, these files had to be parsed and the audio was converted and downsampled to a 16kHz Wave-file.\n",
    "Information about the Speakers, Chapters and Books were extracted from the respective files (`SPEAKERS.TXT`, `CHAPTERS.TXT` and `BOOKS.TXT`).\n",
    "\n",
    "#### Unaligned speech segments\n",
    "_Speech segments_ could be derived by exploiting the temporal information from aligned parts of the corpus. Short intervals between speeches were interpreted as _pause segments_. However, since not all passages in the recordings were aligned with text from the underlying book, not all intervals between speech segments correspond to speech pauses. By comparing the transcripts of aligned speech sequences with the underlying book text any time interval could be classified as either _unaligned speech_ or a pause segment: \n",
    "\n",
    "* if the concatenated transcripts of two subsequent aligned speech segments did not match with any part of the book text, the transcript contains \"holes\" (i.e. parts of the book were left out during alignment). The interval between the aligned speech segments were then treated as _unaligned speech_ and may contain any number of pause segments at the start, beginning or within the interval. \n",
    "* If the concatenated transcripts of two subsequent aligned speech segments roughly matched up with some passage from the book text, the speech segments were deemed consistent (i.e. the recordings of the speech segments were made from subsequent passages of text). The interval between the speech segments were then treated as a _pause segment_.\n",
    "\n",
    "Since the encoding of the transcripts from the _LibriSpeech_ corpus deviated from the original book text, the comparison between transcripts and book text was made using normalized versions of both. Normalization was acquired through removing non-ASCII characters and punctuation, replacing multiple whitespaces with a single and converting everything to uppercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Download raw data\n",
    "To create the LibriSpeech corpus you first need to download the raw data. The files are over 80GB and need to be extracted, so this might take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(download_ls_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus\n",
    "We need to extract the alignments from the segmentation information of the raw data. For this, the downloaded data needs to be converted to corpus entries. **This process takes several hours, so you might want to do this just before knocking-off time!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_ls_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Explore corpus\n",
    "Again, let's load the newly created corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_corpus = load_corpus(ls_target_root)\n",
    "ls_corpus.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "To see if everything worked as expected let's check out a sample alignment. You can execute the cell below to show a random alignment from a random corpus entry. You can execute the cell several times to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = random.choice(ls_corpus)\n",
    "# corpus_entry = ls_corpus[0]\n",
    "corpus_entry.summary()\n",
    "show_corpus_entry(corpus_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook showed how raw data from _ReadyLingua_ and _LibriSpeech_ was pre-processed and stored in corpora using a common format. The summary of the corpora also showed significant difference between the corpora:\n",
    "\n",
    "The _ReadyLingua_ corpus contains only 27 hours of transcribed audio in different languages. The amount of recordings is heavily unbalanced, both in number and total lengh. Also, some recordings exhibit audible effects like reverb. Recordings in this corpus partly overlap with the _LibriSpeech_ corpus.\n",
    "\n",
    "In contrast, the _LibriSpeech_ corpus contains roughly 1400 hours of transcribed audio in English. The raw data for corpus was specifically created for ASR. Because of the sheer amount of data, this corpus is suited much more to train a Neural Network. Also, the recording quality is more homogenous than in the _ReadyLingua_ corpus and free from distortions like echo and reverb. Another advantage of this corpus is that the data has already been split into training-, validation- and test-set. This split was made carefully so that they are disjoint, i.e. the audio of each speaker is assigned to exactly one set. Also, the distribution of male/female speakers is similar between these sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
