{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IP8: Creation of Labelled Data\n",
    "Define a path to an empty directory with enough free storage where the labelled data can be stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_root = r'E:/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's define the imports and some helper functions before we start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import HTML, Audio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, Audio\n",
    "\n",
    "from create_labelled_data import create_subsets\n",
    "from corpus_util import *\n",
    "from audio_util import *\n",
    "from data_util import *\n",
    "\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "from IPython.display import HTML, Audio\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from corpus_util import *\n",
    "from audio_util import *\n",
    "from data_util import *\n",
    "\n",
    "rl_corpus_root = os.path.join(target_root, 'readylingua-corpus')\n",
    "ls_corpus_root = os.path.join(target_root, 'librispeech-corpus')\n",
    "\n",
    "rl_data_root = os.path.join(target_root, 'readylingua-data')\n",
    "ls_data_root = os.path.join(target_root, 'librispeech-data')\n",
    "\n",
    "rl_corpus_path = os.path.join(rl_corpus_root, 'readylingua.corpus')\n",
    "ls_corpus_path = os.path.join(ls_corpus_root, 'librispeech.corpus')\n",
    "\n",
    "\n",
    "def show_labelled_data(corpus_entry):\n",
    "    rate, audio = corpus_entry.audio\n",
    "    \n",
    "    display(Audio(data=audio, rate=rate))\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax_wave = show_wave(fig, audio, corpus_entry.audio_file)\n",
    "    \n",
    "    freqs, times, spectrogram = log_specgram(audio, rate)\n",
    "    ax_spec, extent = show_spectrogram(fig, freqs, times, spectrogram)\n",
    "    left, right, bottom, top = extent\n",
    "\n",
    "    x, y, _ = load_labelled_data(corpus_entry, r'E:\\readylingua-data')\n",
    "    \n",
    "    boundaries = calculate_pause_boundaries(y)\n",
    "    show_pause_segments(ax_wave, boundaries, len(audio))\n",
    "    show_pause_segments(ax_spec, boundaries, right-left)\n",
    "    \n",
    "def show_wave(fig, audio, audio_file):\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.set_title('Raw wave of ' + audio_file)\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.plot(np.linspace(0, len(audio), len(audio)), audio)\n",
    "    return ax1\n",
    "\n",
    "def show_spectrogram(fig, freqs, times, spectrogram):\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    extent = [times.min(), times.max(), freqs.min(), freqs.max()]\n",
    "    ax2.imshow(spectrogram.T, aspect='auto', origin='lower', extent=extent)\n",
    "    ax2.set_yticks(freqs[::16])\n",
    "    ax2.set_xticks(times[::int(len(times)/10)])\n",
    "    ax2.set_title('Spectrogram of ' + corpus_entry.audio_file)\n",
    "    ax2.set_ylabel('Freqs in Hz')\n",
    "    ax2.set_xlabel('Seconds')\n",
    "    return ax2, extent\n",
    "\n",
    "def show_pause_segments(ax, boundaries, x_width):\n",
    "    for pause_start, pause_end in boundaries:\n",
    "        ax.axvspan(pause_start*x_width, pause_end*x_width, color='red', alpha=0.5)\n",
    "    \n",
    "def calculate_pause_boundaries(y):\n",
    "    boundaries = np.flatnonzero(np.diff(np.r_[0,y,0]) != 0).reshape(-1,2) - [0,1]\n",
    "    return [tuple(elem) for elem in boundaries / len(y)]\n",
    "\n",
    "    \n",
    "def on_create_data_rl_button_click(sender):\n",
    "    rl_target_root = os.path.join(target_root, 'readylingua-data')\n",
    "    create_subsets(ls_corpus, rl_target_root)\n",
    "    \n",
    "def on_create_data_ls_button_click(sender):\n",
    "    ls_target_root = os.path.join(target_root, 'librispeech-data')\n",
    "    create_subsets(ls_corpus, ls_target_root)      \n",
    "    \n",
    "# UI elements\n",
    "layout = widgets.Layout(width='250px', height='50px')\n",
    "create_data_rl_btn = widgets.Button(description=\"Create labelled data for ReadyLingua\", button_style='info', layout=layout, icon='download')\n",
    "create_data_rl_btn.on_click(on_create_data_rl_button_click)\n",
    "create_data_ls_btn = widgets.Button(description=\"Create labelled data for LibriSpeech\", button_style='info', layout=layout, icon='download')\n",
    "create_data_ls_btn.on_click(on_create_data_ls_button_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the corpora we can start creating labelled data to train an RNN. In the following sections the following variable namesare used to denote the parts of this data:\n",
    "\n",
    "* `X`: The training data, i.e. the spectrograms (one spectrogram per corpus entry)\n",
    "* `Y`: The training labels, i.e. sequences of zeroes when text is being spoken and sequences of ones when nothing is being spoken (i.e. silence or only background noise)\n",
    "\n",
    "Let's load the created corpora to make them available to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_corpus = load_corpus(rl_corpus_path)\n",
    "rl_corpus = load_corpus(ls_corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Dev/Test split\n",
    "The labelled data is split into subsets for training (_train-set_), validation (_dev-set_) and model evaluation (_test-set_). Since the corpora were constructed from different amounts of raw data, they vary in size and probability distribution (number of languages, homogeneity of the recording quality, ratio of male vs. female speakers, presence of distortions like reverb, echo or overdrive, and many more). Since the starting point for the creation of the corpus was so different, different approaches were taken to split the corpus up into train-, dev- and test-set.\n",
    "\n",
    "#### ReadyLingua corpus\n",
    "tbd.\n",
    "\n",
    "#### LibriSpeech corpus\n",
    "The LibriSpeech raw data is already split into train-, dev- and test-set. Each chapter is read by a different speaker. Each speaker is only contained in one of the subsets. Efforts have been made to keep the different sets within the same probability distributions (regarding to accents, ratio of male/female speakers, ...). To leverage these efforts, the corresponding corpus entries created from the raw data are kept in the same sets.\n",
    "\n",
    "---\n",
    "\n",
    "You can explore the subsets by executing the cell below to see the number of samples (corpus entries) in each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train, ls_dev, ls_test = ls_corpus.train_dev_test_split()\n",
    "print(f'#train-samples: {len(ls_train)}, #dev-samples: {len(ls_dev)}, #test-samples: {len(ls_test)}')\n",
    "\n",
    "rl_train, rl_dev, rl_test = rl_corpus.train_dev_test_split()\n",
    "print(f'#train-samples: {len(rl_train)}, #dev-samples: {len(rl_dev)}, #test-samples: {len(rl_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  From corpus entries to spectrograms\n",
    "In order to train an RNN, each sample needs to be converted into some sort of sequence. In this case the samples are the audio files from the corpus entries and the sequences are their spectrograms. You can explore a random sample together with its spectrogram by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = random.choice(ls_corpus)\n",
    "show_spectrogram(random_entry.audio_file)\n",
    "show_audio(random_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spectrogram is now created as a matrix `x` for every single corpus entry. All the `x`-es are then collected and form `X`. For each corpus this gives us three seperate files (`X_train.ls`, `X_dev.ls` and `X_test.ls` for LibriSpeech data and `X_train.rl`, `X_dev.rl` and `X_test.rl` for ReadyLingua data).\n",
    "\n",
    "Accordingly, the segmentation information (speech- and pause-segments) is obtained from each corpus entry to form a label vector `y` for each sample. All label vectors arae collected into the Label matrix `Y`. Like for the data part, also the labels are kept in three seperate files per corpus (`Y_train.ls`, `Y_dev.ls` and `Y_test.ls` resp. `Y_train.rl`, `Y_dev.rl` and `Y_test.rl`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the spectrograms and labels\n",
    "\n",
    "Click the button below to start processing the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(widgets.HBox([create_data_rl_btn, create_data_ls_btn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the labelled data\n",
    "After the data has been processed, we can visualize a sample by comparing a spectrogram with its corresponding label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_entry = random.choice(rl_corpus)\n",
    "show_labelled_data(corpus_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
