{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IP8\n",
    "This IPython notebook documents and visualizes some crucial steps made during the progress of the project. I should help the reader understand how and why decisions were made as well as illustrate some important concepts with examples.\n",
    "\n",
    "## Corpora\n",
    "Every Neural Network needs training data. The RNN used in this project is no exception. Since this project is about Forced Alignment (FA), training data consisted of pre-aligned audio and transcript data. This training data was derived from the following resources:\n",
    "\n",
    "* **ReadyLingua**: Aligned data in various languages and by various speakers provided by ReadyLingua.\n",
    "* **LibriSpeech**: Open Source ASR corpus (http://openslr.org/12/) containing roughly 1000h aligned speech data.\n",
    "* ... (additional Corpora tbd.)\n",
    "\n",
    "In order to all data for training, it had to be converted to a common format. Since (to my knowledge) there is not a standardized format for FA, I had to define one myself. Therefore I went for the following structure for a single corpus entry:\n",
    "\n",
    "```JSON\n",
    "// definition of the corpus\n",
    "corpus = [corpus_entry]\n",
    "\n",
    "// definition of an individual corpus entry\n",
    "corpus_entry = \n",
    "{\n",
    "    'audio': [byte],                 // bytes from the audio file\n",
    "    'transcript': string,            // raw (unaligned) text \n",
    "    'speech-pauses': [speech_pause], // segmentation of the audio file into speech and pause segments\n",
    "    'alignment': [alignment]         // alignment of bits of the unaligned text with the audio\n",
    "}\n",
    "\n",
    "// definition of a speech or pause segment\n",
    "speech_pause = \n",
    "{\n",
    "    'id': string,                    // some unique identifier\n",
    "    'start': int,                    // start frame of the segment\n",
    "    'end': int,                      // end frame of the speech pause\n",
    "    'class': string                  // 'speech' for a speech segment, 'pause' for a pause segment\n",
    "}\n",
    "\n",
    "// definition of an alignment\n",
    "alignment = \n",
    "{\n",
    "    'text': string,                  // text that is being spoken in the audio\n",
    "    'start': int,                    // start frame in the audio file (when the text starts)\n",
    "    'end': int                       // end frame in the audio file (when the text stops)\n",
    "}\n",
    "```\n",
    "\n",
    "### ReadyLingua Corpus\n",
    "ReadyLingua (RL) provides alignment data distributed over several files files:\n",
    "\n",
    "* `*.wav`: Audio file containing the speech\n",
    "* `*.txt`: UTF-8 encoded (unaligned) transcript\n",
    "* `* - Segmentation.xml`: file comtaining the definition of speech- and pause segments\n",
    "```XML\n",
    "<Segmentation>\n",
    "    <SelectionExtension>0</SelectionExtension>\n",
    "    <Segments>\n",
    "\t<Segment id=\"1\" start=\"83790\" end=\"122598\" class=\"Speech\" uid=\"5\" />\n",
    "\t...\n",
    "    </Segments>\n",
    "    <Segmenter SegmenterType=\"SICore.AudioSegmentation.EnergyThresholding\">\n",
    "        <MaxSpeechSegmentExtension>50</MaxSpeechSegmentExtension>\n",
    "        <Length>-1</Length>\n",
    "        <Energies>\n",
    "            <Value id=\"1\" value=\"0\" />\n",
    "            ...\n",
    "        </Energies>\n",
    "        <OriginalSegments>\n",
    "            <Segment id=\"1\" start=\"83790\" end=\"100548\" class=\"Speech\" uid=\"2\" />\n",
    "            ...\n",
    "        </OriginalSegments>\n",
    "        <EnergyPeak>3569753</EnergyPeak>\n",
    "        <StepSize>441</StepSize>\n",
    "        <ITL>146139</ITL>\n",
    "        <ITU>730695</ITU>\n",
    "        <LastUid>2048</LastUid>\n",
    "        <MinPauseDuration>200</MinPauseDuration>\n",
    "        <MinSpeechDuration>150</MinSpeechDuration>\n",
    "        <BeginOfSilence>1546255</BeginOfSilence>\n",
    "        <SilenceLength>100</SilenceLength>\n",
    "        <ThresholdCorrectionFactor>1</ThresholdCorrectionFactor>\n",
    "    </Segmenter>\n",
    "</Segmentation>\n",
    "```\n",
    "* `* - Index.xml`: file containing the actual alignments of text to audio\n",
    "```XML\n",
    "<XMLIndexFile>\n",
    "    <Version>2.0.0</Version>\n",
    "    <SamplingRate>44100</SamplingRate>\n",
    "    <NumberOfIndices>91</NumberOfIndices>\n",
    "    <TextAudioIndex>\n",
    "        <TextStartPos>0</TextStartPos>\n",
    "        <TextEndPos>36</TextEndPos>\n",
    "        <AudioStartPos>952101</AudioStartPos>\n",
    "        <AudioEndPos>1062000</AudioEndPos>\n",
    "        <SpeakerKey>-1</SpeakerKey>\n",
    "    </TextAudioIndex>\n",
    "    ...\n",
    "</XMLIndexFile>    \n",
    "```\n",
    "* `* - Project.xml`: Project file binding the different files together for a corpus entry (note: this file is optional, i.e. there may be not project file for a corpus entry)\n",
    "\n",
    "Corpus entries are organized in a folder hierarchy. There is a fileset for each corpus entry. Usually, the files for a specific corpus entry reside in a leaf directory (i.e. a directory without further subdirectories). If there is a project file, this file is used to locate the files needed to \n",
    "\n",
    "Audio data is provided as Wave-Files with a sampling rate of 44,1 kHz (stereo). Because most ASR corpora provide their recordings with a sampling rate of 16 kHz the files were downsampled and the alignment information adjusted. The raw transcription is integrated as-is. The XML files are parsed to extract the alignment data. Alignment-, textual and downsampled audio data are merged into a corpus entry as described above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ReadyLingua corpus...\n",
      "...done! Loaded 1 corpus entries\n"
     ]
    }
   ],
   "source": [
    "from corpus_util import *\n",
    "\n",
    "# load corpora\n",
    "print('loading ReadyLingua corpus...')\n",
    "rl_corpus = load_corpus('readylingua/readylingua.corpus')\n",
    "print(f'...done! Loaded {len(rl_corpus)} corpus entries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "def select_entry(corpus, ix=None):\n",
    "    return corpus[ix] if ix else corpus[randint(0, len(corpus)) - 1]\n",
    "\n",
    "def select_alignment(audio, alignments, ix=None):\n",
    "    alignment_ix = ix or randint(0, len(alignments) - 1)\n",
    "    \n",
    "    alignment = alignments[alignment_ix]\n",
    "    start = alignment['start']\n",
    "    end = alignment['end']\n",
    "    alignment_audio = audio[start:end]\n",
    "    alignment_text = alignment['text']\n",
    "    return alignment_audio, alignment_text\n",
    "\n",
    "# display 5 random audio with aligned text\n",
    "for i in range(5):\n",
    "    corpus_entry = select_entry(rl_corpus)\n",
    "    alignment_audio, alignment_text = select_alignment(corpus_entry['audio'], corpus_entry['alignments'])\n",
    "    print(alignment_audio)\n",
    "    #IPython.display.Audio(filename=alignment_audio)\n",
    "    IPython.display.HTML(f'<p>{alignment_text}</p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
