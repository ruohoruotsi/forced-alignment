{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IP8\n",
    "This IPython notebook documents and visualizes some crucial steps made during the progress of the project. I should help the reader understand how and why decisions were made as well as illustrate some important concepts with examples.\n",
    "\n",
    "## Corpora\n",
    "Every Neural Network needs training data. The RNN used in this project is no exception. Since this project is about Forced Alignment (FA), training data consisted of pre-aligned audio and transcript data. This training data was derived from the following resources:\n",
    "\n",
    "* **ReadyLingua**: Aligned data in various languages and by various speakers provided by ReadyLingua.\n",
    "* **LibriSpeech**: Open Source ASR corpus (http://openslr.org/12/) containing roughly 1000h aligned speech data.\n",
    "* ... (additional Corpora tbd.)\n",
    "\n",
    "In order to all data for training, it had to be converted to a common format. Since (to my knowledge) there is not a standardized format for FA, I had to define one myself. Therefore I went for the following structure for a single corpus entry:\n",
    "\n",
    "```JSON\n",
    "// definition of the corpus\n",
    "corpus = [corpus_entry]\n",
    "\n",
    "// definition of an individual corpus entry\n",
    "corpus_entry = \n",
    "{\n",
    "    'audio': [byte],                 // bytes from the audio file\n",
    "    'transcript': string,            // raw (unaligned) text \n",
    "    'speech-pauses': [speech_pause], // segmentation of the audio file into speech and pause segments\n",
    "    'alignment': [alignment]         // alignment of bits of the unaligned text with the audio\n",
    "}\n",
    "\n",
    "// definition of a speech or pause segment\n",
    "speech_pause = \n",
    "{\n",
    "    'id': string,                    // some unique identifier\n",
    "    'start': int,                    // start frame of the segment\n",
    "    'end': int,                      // end frame of the speech pause\n",
    "    'class': string                  // 'speech' for a speech segment, 'pause' for a pause segment\n",
    "}\n",
    "\n",
    "// definition of an alignment\n",
    "alignment = \n",
    "{\n",
    "    'text': string,                  // text that is being spoken in the audio\n",
    "    'start': int,                    // start frame in the audio file (when the text starts)\n",
    "    'end': int                       // end frame in the audio file (when the text stops)\n",
    "}\n",
    "```\n",
    "\n",
    "### ReadyLingua Corpus\n",
    "ReadyLingua (RL) provides alignment data in the following files:\n",
    "\n",
    "* `*.wav`: Audio file containing the speech\n",
    "* `\n",
    "audio as Wave-Files () with a sampling rate of 44,1 kHz (stereo). Because most ASR corpora provide their recordings with a sampling rate of 16 kHz the files were downsampled and the alignment information adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
