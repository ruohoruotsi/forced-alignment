{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports and some helper functions. You don't need to change anything in here!\n",
    "\"\"\"\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tarfile\n",
    "from corpus_util import *\n",
    "from random import randint\n",
    "import readylingua_corpus\n",
    "import librispeech_corpus\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display, Audio, HTML\n",
    "\n",
    "# placeholder variables which must be overridden by custom values\n",
    "root_path = r'E:/'                              # path to root directory with enough free storage\n",
    "rl_source_path = r'D:\\corpus\\readylingua-raw'   # path to directory where raw ReadyLingua data is stored\n",
    "ls_source_path = r'D:\\corpus\\librispeech-raw'    # path to directory where LibriSpeech files are/will be downloaded (will be changed if files are downloaded)\n",
    "\n",
    "# default directories which must not be overridden by custom values\n",
    "rl_target_dir = 'readylingua-corpus'      # name of target directory for ReadyLingua corpus files (default value)\n",
    "ls_target_dir = 'librispeech-corpus'      # name of target directory for LibriSpeech corpus files (default value)\n",
    "rl_corpus_file = os.path.join(root_path, rl_target_dir, 'readylingua.corpus')  # path to ReadyLingua corpus file (will be set after corpus has been created)\n",
    "ls_corpus_file = os.path.join(root_path, ls_target_dir, 'librispeech.corpus')  # path to LibriSpeech corpus file (will be set after corpus has been created)\n",
    "\n",
    "def select_entry(corpus, ix=None):\n",
    "    ix = ix if ix is not None else randint(0, len(corpus) - 1)\n",
    "    return corpus[ix]\n",
    "\n",
    "def select_alignment(corpus_entry, ix=None):\n",
    "    ix = ix if ix is not None else randint(0, len(corpus_entry.alignments) - 1)\n",
    "    return corpus_entry.alignments[ix]\n",
    "\n",
    "def display_random_entry(corpus, ix_entry=None, ix_alignment=None):\n",
    "    corpus_entry = select_entry(corpus, ix_entry)\n",
    "    alignment = select_alignment(corpus_entry, ix_alignment)\n",
    "    \n",
    "    entry_title = HTML(f'<strong>Sample corpus entry: {corpus_entry.name}</strong> ({corpus_entry.original_path})')\n",
    "    entry_audio = Audio(corpus_entry.audio_file)\n",
    "    entry_text = widgets.Accordion(children=[widgets.HTML(f'<pre>{corpus_entry.transcript}</pre>')], selected_index=None)\n",
    "    entry_text.set_title(0, 'Transcript')\n",
    "    \n",
    "    alignment_title = HTML(f'<strong>Sample alignment</strong> (start_frame={alignment.start_frame}, end_frame={alignment.end_frame})')\n",
    "    alignment_audio = Audio(data = alignment.audio, rate=16000.0)\n",
    "    alignment_text = HTML(f'<pre>{alignment.text}</pre>')\n",
    "    \n",
    "    display(entry_title) \n",
    "    display(entry_audio) \n",
    "    display(entry_text) \n",
    "    display(alignment_title) \n",
    "    display(alignment_audio) \n",
    "    display(alignment_text) \n",
    "    \n",
    "def download_file(url, target_dir):\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length', 0)); \n",
    "    block_size = 1024\n",
    "    wrote = 0 \n",
    "    tmp_file = os.path.join(root_path, 'download.tmp')\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    \n",
    "    with open(tmp_file, 'wb') as f:\n",
    "        with tqdm(r.iter_content(32*block_size), total=total_size , unit='B', unit_divisor=block_size, unit_scale=True) as pbar:\n",
    "            for data in r.iter_content(32*1024):\n",
    "                wrote = wrote  + len(data)\n",
    "                f.write(data)\n",
    "                pbar.update(len(data))\n",
    "                                   \n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        print(\"ERROR, something went wrong\")  \n",
    "        \n",
    "    print('Extracting data...')\n",
    "    tar = tarfile.open(tmp_file, \"r:gz\")\n",
    "    tar.extractall(target_dir)\n",
    "    tar.close()\n",
    "    print(f'... done! File downloaded and extracted to: {target_dir}')\n",
    "    os.remove(tmp_file)\n",
    "    \n",
    "def on_download_ls_button_click(sender):\n",
    "    global ls_source_path\n",
    "    if os.path.exists(ls_source_path) and os.listdir(ls_source_path):\n",
    "        print(f'Directory {ls_source_path} exists and is not empty. Assuming LibriSpeech data was already downloaded there.')\n",
    "        return\n",
    "        \n",
    "    print('Downloading LibriSpeech data... Get lunch or something!')\n",
    "    if os.path.isabs(ls_source_path):\n",
    "        # path is absolute --> use this path as target directory for the download\n",
    "        target_dir = ls_source_path\n",
    "    else:\n",
    "        # path is relative --> create relative subdirectory under root_path\n",
    "        target_dir = os.path.join(root_path, ls_source_path)\n",
    "    print('Download 1/2: Audio data')\n",
    "    download_file('http://www.openslr.org/resources/12/dev-clean.tar.gz', os.path.join(target_dir, 'librispeech-audio'))\n",
    "    print('Download 2/2: Text data')\n",
    "    download_file('http://www.openslr.org/resources/12/original-books.tar.gz', os.path.join(target_dir, 'librispeech-books'))\n",
    "    ls_source_path = target_dir\n",
    "    \n",
    "def on_create_rl_button_click(sender):\n",
    "    global rl_corpus_file\n",
    "    print('Creating ReadyLingua corpus... Get a coffee or something!')\n",
    "    if os.path.isabs(rl_source_path):\n",
    "        # path to RL raw data was given as an absolute path --> use this path\n",
    "        source_root = rl_source_path\n",
    "    else:\n",
    "        # path to RL raw data was given as an relative path --> create absolute path from root_path\n",
    "        source_root = os.path.join(root_path, rl_source_path)\n",
    "    target_root = os.path.join(root_path, rl_target_dir)\n",
    "    print(f'source_root={source_root}, target_root={target_root}')\n",
    "    rl_corpus_file = readylingua_corpus.create_corpus(source_root=source_root, target_root=target_root)\n",
    "    print(f'Done! Corpus file created in {rl_corpus_file}')\n",
    "    \n",
    "def on_create_ls_button_click(sender):\n",
    "    global ls_corpus_file\n",
    "    print('Creating LibriSpeech corpus... Go to bed or something!')\n",
    "    source_root = ls_source_path\n",
    "    target_root = os.path.join(root_path, ls_target_dir)\n",
    "    print(f'source_root={source_root}, target_root={target_root}')\n",
    "    ls_corpus_file = librispeech_corpus.create_corpus(source_root=source_root, target_root=target_root)\n",
    "    print(f'Done! Corpus file created in {ls_corpus_file}')\n",
    "    \n",
    "layout = widgets.Layout(width='250px', height='50px')\n",
    "download_ls_button = widgets.Button(description=\"Download LibriSpeech Data\", button_style='info', layout=layout, icon='download')\n",
    "download_ls_button.on_click(on_download_ls_button_click)\n",
    "create_rl_button = widgets.Button(description=\"Create ReadyLingua Corpus\", button_style='warning', layout=layout, icon=\"book\", tooltip='~5 minutes')\n",
    "create_rl_button.on_click(on_create_rl_button_click)\n",
    "create_ls_button = widgets.Button(description=\"Create LibriSpeech Corpus\", button_style='warning', layout=layout, icon=\"book\", tooltip='~5 hours')\n",
    "create_ls_button.on_click(on_create_ls_button_click)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IP8\n",
    "This IPython notebook documents and visualizes some crucial steps made during the progress of the project. I should help the reader understand how and why decisions were made as well as illustrate some important concepts with examples.\n",
    "\n",
    "## Prerequisites\n",
    "This project was built using Python 3.6 and Anaconda 3. Please install the packages listed in `requirements.txt`. Additionally, you need the following tools and resources:\n",
    "\n",
    "* [FFMPEG](http://www.ffmpeg.org/): for the conversion and/or resampling of audio files\n",
    "* ReadyLingua raw data: You need to get the raw files somehow and store them on your machine.\n",
    "\n",
    "### Set root directory\n",
    "This project uses several corpora as training data. The corpora need to be created and trained, which requires approximately 350GB of free storage on the harddisk with the currently included corpora. Note: Final storage use might be lower since some of the memory is only used temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'E:\\\\' # specify a root directory with at least 350GB of free storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creation of Corpora\n",
    "Every Neural Network needs training data. The RNN used in this project is no exception. Since this project is about Forced Alignment (FA), training data consisted of pre-aligned audio and transcript data. This training data was derived from the following resources:\n",
    "\n",
    "* ReadyLingua\n",
    "* LibriSpeech\n",
    "* ... (additional Corpora tbd.)\n",
    "\n",
    "Those corpora contain alignment information which were extracted and stored in **corpus_entries**. Those corpus entries can be created in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus entries\n",
    "In order to allow data from all sources for training, it had to be converted to a common format. Since (to my knowledge) there is not a standardized format for FA, I had to define one myself. Therefore I went for the following structure for a single corpus entry:\n",
    "\n",
    "```JSON\n",
    "// definition of the corpus\n",
    "corpus = [corpus_entry]\n",
    "\n",
    "// definition of an individual corpus entry\n",
    "corpus_entry = \n",
    "{\n",
    "    'audio': [byte],                 // bytes from the audio file\n",
    "    'transcript': string,            // raw (unaligned) text \n",
    "    'speech-pauses': [speech_pause], // segmentation of the audio file into speech and pause segments\n",
    "    'alignment': [alignment]         // alignment of bits of the unaligned text with the audio\n",
    "}\n",
    "\n",
    "// definition of a speech or pause segment\n",
    "speech_pause = \n",
    "{\n",
    "    'id': string,                    // some unique identifier\n",
    "    'start': int,                    // start frame of the segment\n",
    "    'end': int,                      // end frame of the speech pause\n",
    "    'class': string                  // 'speech' for a speech segment, 'pause' for a pause segment\n",
    "}\n",
    "\n",
    "// definition of an alignment\n",
    "alignment = \n",
    "{\n",
    "    'text': string,                  // text that is being spoken in the audio\n",
    "    'start': int,                    // start frame in the audio file (when the text starts)\n",
    "    'end': int                       // end frame in the audio file (when the text stops)\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ReadyLingua Corpus\n",
    "ReadyLingua (RL) provides alignment data distributed over several files files:\n",
    "\n",
    "* `*.wav`: Audio file containing the speech\n",
    "* `*.txt`: UTF-8 encoded (unaligned) transcript\n",
    "* `* - Segmentation.xml`: file comtaining the definition of speech- and pause segments\n",
    "```XML\n",
    "<Segmentation>\n",
    "    <SelectionExtension>0</SelectionExtension>\n",
    "    <Segments>\n",
    "\t<Segment id=\"1\" start=\"83790\" end=\"122598\" class=\"Speech\" uid=\"5\" />\n",
    "\t...\n",
    "    </Segments>\n",
    "    <Segmenter SegmenterType=\"SICore.AudioSegmentation.EnergyThresholding\">\n",
    "        <MaxSpeechSegmentExtension>50</MaxSpeechSegmentExtension>\n",
    "        <Length>-1</Length>\n",
    "        <Energies>\n",
    "            <Value id=\"1\" value=\"0\" />\n",
    "            ...\n",
    "        </Energies>\n",
    "        <OriginalSegments>\n",
    "            <Segment id=\"1\" start=\"83790\" end=\"100548\" class=\"Speech\" uid=\"2\" />\n",
    "            ...\n",
    "        </OriginalSegments>\n",
    "        <EnergyPeak>3569753</EnergyPeak>\n",
    "        <StepSize>441</StepSize>\n",
    "        <ITL>146139</ITL>\n",
    "        <ITU>730695</ITU>\n",
    "        <LastUid>2048</LastUid>\n",
    "        <MinPauseDuration>200</MinPauseDuration>\n",
    "        <MinSpeechDuration>150</MinSpeechDuration>\n",
    "        <BeginOfSilence>1546255</BeginOfSilence>\n",
    "        <SilenceLength>100</SilenceLength>\n",
    "        <ThresholdCorrectionFactor>1</ThresholdCorrectionFactor>\n",
    "    </Segmenter>\n",
    "</Segmentation>\n",
    "```\n",
    "* `* - Index.xml`: file containing the actual alignments of text to audio\n",
    "```XML\n",
    "<XMLIndexFile>\n",
    "    <Version>2.0.0</Version>\n",
    "    <SamplingRate>44100</SamplingRate>\n",
    "    <NumberOfIndices>91</NumberOfIndices>\n",
    "    <TextAudioIndex>\n",
    "        <TextStartPos>0</TextStartPos>\n",
    "        <TextEndPos>36</TextEndPos>\n",
    "        <AudioStartPos>952101</AudioStartPos>\n",
    "        <AudioEndPos>1062000</AudioEndPos>\n",
    "        <SpeakerKey>-1</SpeakerKey>\n",
    "    </TextAudioIndex>\n",
    "    ...\n",
    "</XMLIndexFile>    \n",
    "```\n",
    "* `* - Project.xml`: Project file binding the different files together for a corpus entry (note: this file is optional, i.e. there may be not project file for a corpus entry)\n",
    "\n",
    "Corpus entries are organized in a folder hierarchy. There is a fileset for each corpus entry. Usually, the files for a specific corpus entry reside in a leaf directory (i.e. a directory without further subdirectories). If there is a project file, this file is used to locate the files needed to \n",
    "\n",
    "Audio data is provided as Wave-Files with a sampling rate of 44,1 kHz (stereo). Because most ASR corpora provide their recordings with a sampling rate of 16 kHz the files were downsampled and the alignment information adjusted. The raw transcription is integrated as-is. The XML files are parsed to extract the alignment data. Alignment-, textual and downsampled audio data are merged into a corpus entry as described above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define location of raw data\n",
    "The pre-aligned ReadyLingua data is not publicly available so you must define where you store the files on your harddisk. Specify the folder below to indicate where the files are stored on your disk. You can enter a relative or an absolute path. **A relative path is assumed to be relative to the previously defined root directory!**\n",
    "\n",
    "**Don't forget to execute the cell to apply the changes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_source_path = r'D:\\corpus\\readylingua-raw' # set this to the (absolute or relative) path to where the ReadyLingua files are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create corpus entries\n",
    "We need to extract the alignments from the segmentation information of the raw data. For this, the downloaded data needs to be converted to corpus entries. This process takes a few minuts, so this is a good time to have a coffee break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_rl_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Explore corpus\n",
    "To see if everything worked as expected let's check out a sample alignment. You can execute the cell below to show a random alignment from a random corpus entry. You can execute the cell several times to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_corpus = load_corpus(rl_corpus_file)\n",
    "display_random_entry(rl_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LibriSpeech Corpus\n",
    "[LibriSpeech](http://www.openslr.org/12/) is an open-source corpus for Automatic Speech Recognition (ASR). It contains recordings of LibriVox' public domain audio books and their transcriptions made by volunteers. The data is evenly distributed in terms of gender, recording length, accent, etc. The corpus is split into training-, dev- and test-set (`train-*.tar.gz`, `dev-*.tar.gz` and `test-*.tar.gz`). However, those sets only contain the transcript as a set of segments and an audio file for each segment. They do not contain any temporal information which is needed for alignment.\n",
    "\n",
    "Luckily, there is also the `original-mp3-tar.gz` for download which contains the original LibriVox mp3 files (from which the corpus was created) along with the alignment information. Alignment is made on utterance level, i.e. the transcript is split up into segments whereas each segment corresponds to an utterance. Segments were derived by allowing splitting on every silence interval longer than 300ms. \n",
    "\n",
    "The data is organized into subdirectories of the following format:\n",
    "\n",
    "    ./LibriSpeech/mp3/{speaker_id}/{chapter_id}/\n",
    "\n",
    "There is one subdirectory containing all the information about a recording. For this project the following files are important:\n",
    "\n",
    "- `{chapter_id}.mp3`: The audio file containing the recording. The audio is mono with a bitrate of 128 kB/s and a sampling rate of 44.1 kHz.\n",
    "- `{speaker_id}-{chapter_id}.seg.txt`: Text file containing temporal information about the segments (one segment per line). The time is indicated in seconds.\n",
    "Example:\n",
    "```\n",
    "14-208_0000 25.16 40.51\n",
    "```\n",
    "- `{speaker_id}-{chapter_id}.trans.txt`: Text file containing the transcriptions of the segments (one segment per line). The transcription is all uppercase and does not contain any punctuation.\n",
    "```\n",
    "14-208_0000 CHAPTER ELEVEN THE MORROW BROUGHT A VERY SOBER LOOKING MORNING THE SUN MAKING ONLY A FEW EFFORTS...\n",
    "```\n",
    "\n",
    "In order to create the corpus, these files had to be parsed and the audio was converted and downsampled to a 16kHz Wave-file.\n",
    "Information about the Speakers, Chapters and Books were extracted from the respective files (`SPEAKERS.TXT`, `CHAPTERS.TXT` and `BOOKS.TXT`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 1: Download raw data\n",
    "To create the LibriSpeech corpus you first need to download the raw data. The files are over 80GB and need to be extracted, so this might take a while... Alternatively, if you have already downloaded the data, you can specify the path to the directory, where you have unpacked the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change this value as follows:\n",
    "# - if you specify an absolute path, this path will be used as source directory for the raw files\n",
    "# - if you specify a relative path, a subdirectory under the root directory is used as source directory for the raw files\n",
    "# In any case, if the directory does nt exist or is empty, the files will be automatically downloaded to this path\n",
    "ls_source_path = r'D:\\corpus\\librispeech-raw'\n",
    "display(download_ls_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create corpus\n",
    "We need to extract the alignments from the segmentation information of the raw data. For this, the downloaded data needs to be converted to corpus entries. This process takes several hours, so you might want to do this just before knocking-off time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_ls_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Step 3: Explore corpus\n",
    "To see if everything worked as expected let's check out a sample alignment. You can execute the cell below to show a random alignment from a random corpus entry. You can execute the cell several times to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_corpus = load_corpus(rl_corpus_file)\n",
    "display_random_entry(ls_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
