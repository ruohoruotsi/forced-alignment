{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IP8: Creation of Corpora\n",
    "This IPython notebook documents and visualizes some crucial steps made during the progress of the project. I should help the reader understand how and why decisions were made as well as illustrate some important concepts with examples.\n",
    "\n",
    "## Prerequisites\n",
    "This project was built using Python 3.6 and Anaconda 3. Please install the packages listed in `requirements.txt`. Additionally, you need the following tools and resources:\n",
    "\n",
    "* [FFMPEG](http://www.ffmpeg.org/): for the conversion and/or resampling of audio files\n",
    "* ReadyLingua raw data: You need to get the raw files somehow and store them on your machine.\n",
    "\n",
    "### Training data\n",
    "Every Neural Network needs training data. The RNN used in this project is no exception. Since this project is about Forced Alignment (FA), training data consisted of pre-aligned audio and transcript data. This training data was derived from the following resources:\n",
    "\n",
    "* ReadyLingua\n",
    "* Migros PodClub\n",
    "* LibriSpeech\n",
    "* ... (additional Corpora tbd.)\n",
    "\n",
    "Data from ReadyLingua and PodClup is not publicly available so you must specify the path to the directory where those files are stored. You must use an absolute path.\n",
    "\n",
    "Data from the LibriSpeech is publicly available. You can specify a folder where those files are stored. You must use an absolute path. If the directory is empty, LibriSpeech data will automatically be downloaded. If the directory is not empty, it is assumed that the data from LibriSpeech was automatically downloaded and extracted in this directory. In this case the directory structure must match the expected structure.\n",
    "\n",
    "\n",
    "### Set directories\n",
    "This project uses several corpora as training data. The corpora need to be created and trained, which requires approximately 350GB of free storage on the harddisk with the currently included corpora. Note: Final storage use might be lower since some of the memory is only used temporarily.\n",
    "\n",
    "**Don't forget to execute the cell to apply the changes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_source_root = r'D:\\corpus\\readylingua-raw'   # path to directory where raw ReadyLingua data is stored\n",
    "ls_source_root = r'D:\\corpus\\librispeech-raw'   # path to directory where LibriSpeech files are/will be downloaded (will be changed if files are downloaded)\n",
    "\n",
    "target_root = r'E:/'                            # path to the directory where the corpora will be created (must have at least 350GB of free storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions\n",
    "Execute the cell below to import modules and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports and some helper functions. You don't need to change anything in here!\n",
    "\"\"\"\n",
    "import tarfile\n",
    "import random\n",
    "from os import listdir, rmdir, remove, makedirs\n",
    "from random import randint\n",
    "from shutil import move\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import requests\n",
    "from os.path import exists\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librispeech_corpus\n",
    "import readylingua_corpus\n",
    "from audio_util import *\n",
    "from corpus_util import *\n",
    "from IPython.display import HTML, Audio\n",
    "import ipywidgets as widgets\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# name of target directory for ReadyLingua corpus files (default value)\n",
    "rl_target_root = os.path.join(target_root, 'readylingua-corpus')\n",
    "# name of target directory for LibriSpeech corpus files (default value)\n",
    "ls_target_root = os.path.join(target_root, 'librispeech-corpus')\n",
    "# path to ReadyLingua corpus file (will be set after corpus has been created)\n",
    "rl_corpus_file = os.path.join(rl_target_root, 'readylingua.corpus')\n",
    "# path to LibriSpeech corpus file (will be set after corpus has been created)\n",
    "ls_corpus_file = os.path.join(ls_target_root, 'librispeech.corpus')\n",
    "\n",
    "def show_corpus_entry(corpus, ix_entry=None, ix_speech=None, ix_pause=None):\n",
    "    corpus_entry = corpus[ix_entry] if ix_entry is not None else random.choice(corpus)\n",
    "    speech = corpus_entry.speech_segments[ix_speech] if ix_speech is not None else random.choice(corpus_entry.speech_segments)\n",
    "    pause = corpus_entry.pause_alignments[ix_pause] if ix_pause is not None else random.choice(corpus_entry.pause_segments)\n",
    "\n",
    "    show_audio(corpus_entry)\n",
    "    show_segment(speech)\n",
    "    show_segment(pause)\n",
    "\n",
    "\n",
    "def show_audio(corpus_entry):\n",
    "    entry_title = HTML(f\"\"\"\n",
    "    <h3>Sample corpus entry: {corpus_entry.name}</h3>\n",
    "    <p><strong>Path to raw data</strong>: {corpus_entry.original_path}</p>\n",
    "    \"\"\")\n",
    "    entry_audio = Audio(corpus_entry.audio_file)\n",
    "    entry_text = widgets.Accordion(children=[widgets.HTML(f'<pre>{corpus_entry.transcription}</pre>')], selected_index=None)\n",
    "    entry_text.set_title(0, 'Transcription')\n",
    "    \n",
    "    display(entry_title)\n",
    "    display(entry_audio)\n",
    "    display(entry_text)\n",
    "    \n",
    "def show_segment(segment):\n",
    "    segment_title = HTML(f'<strong>Sample alignment</strong> (start_frame={segment.start_frame}, end_frame={segment.end_frame})')\n",
    "    segment_audio = Audio(data=segment.audio, rate=16000.0)\n",
    "\n",
    "    display(segment_title)\n",
    "    display(segment_audio)\n",
    "    if segment.text:\n",
    "        segment_text = HTML(f'<pre>{segment.text}</pre>')\n",
    "        display(segment_text)\n",
    "\n",
    "\n",
    "def download_file(url, target_dir):\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length', 0));\n",
    "    block_size = 1024\n",
    "    wrote = 0\n",
    "    tmp_file = os.path.join(target_dir, 'download.tmp')\n",
    "    if not exists(target_dir):\n",
    "        makedirs(target_dir)\n",
    "\n",
    "    with open(tmp_file, 'wb') as f:\n",
    "        with tqdm(r.iter_content(32 * block_size), total=total_size, unit='B', unit_divisor=block_size,\n",
    "                  unit_scale=True) as pbar:\n",
    "            for data in r.iter_content(32 * 1024):\n",
    "                wrote = wrote + len(data)\n",
    "                f.write(data)\n",
    "                pbar.update(len(data))\n",
    "\n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "\n",
    "    print('Extracting data...')\n",
    "    tar = tarfile.open(tmp_file, \"r:gz\")\n",
    "    tar.extractall(target_dir)\n",
    "    tar.close()\n",
    "\n",
    "    remove(tmp_file)\n",
    "\n",
    "\n",
    "def move_files(src_dir, target_dir):\n",
    "    for filename in listdir(src_dir):\n",
    "        move(os.path.join(src_dir, filename), os.path.join(target_dir, filename))\n",
    "    rmdir(src_dir)\n",
    "\n",
    "\n",
    "def on_download_ls_button_click(sender):\n",
    "    global ls_source_root\n",
    "    print('Downloading LibriSpeech data... Get lunch or something!')\n",
    "    print('Download 1/2: Audio data')\n",
    "    download_dir = os.path.join(ls_source_root, 'audio')\n",
    "    if exists(download_dir) and listdir(download_dir):\n",
    "        print(f'Directory {download_dir} exists and is not empty. Assuming data was already downloaded there.')\n",
    "    else:\n",
    "        download_file('http://www.openslr.org/resources/12/original-mp3.tar.gz', download_dir)\n",
    "        print('Done! Moving files...')\n",
    "        move_files(os.path.join(download_dir, 'LibriSpeech'), download_dir)\n",
    "\n",
    "    print('Download 2/2: Text data')\n",
    "    download_dir = os.path.join(ls_source_root, 'books')\n",
    "    if exists(download_dir) and listdir(download_dir):\n",
    "        print(f'Directory {download_dir} exists and is not empty. Assuming data was already downloaded there.')\n",
    "    else:\n",
    "        download_file('http://www.openslr.org/resources/12/original-books.tar.gz', download_dir)\n",
    "        move_files(os.path.join(download_dir, 'LibriSpeech'), download_dir)\n",
    "        makedirs(os.path.join(download_dir, 'utf-8'))\n",
    "        move_files(os.path.join(download_dir, 'books', 'utf-8'), os.path.join(download_dir, 'utf-8'))\n",
    "        delete_directory = os.path.join(download_dir, 'books')\n",
    "        print(f'Done! Please delete {delete_directory} manually (not needed)')\n",
    "\n",
    "    print(f'Files downloaded and extracted to: {ls_source_root}')\n",
    "\n",
    "\n",
    "def on_create_rl_button_click(sender):\n",
    "    global rl_corpus_file\n",
    "    print('Creating ReadyLingua corpus... Get a coffee or something!')\n",
    "    rl_corpus, rl_corpus_file = readylingua_corpus.create_corpus(source_root=rl_source_root, target_root=rl_target_root)\n",
    "    print(f'Done! Corpus with {len(rl_corpus)} entries saved to {rl_corpus_file}')\n",
    "\n",
    "\n",
    "def on_create_ls_button_click(sender):\n",
    "    global ls_corpus_file\n",
    "    print('Creating LibriSpeech corpus... Go to bed or something!')\n",
    "    ls_corpus, ls_corpus_file = librispeech_corpus.create_corpus(source_root=ls_source_root, target_root=ls_target_root)\n",
    "    print(f'Done! Corpus with {len(ls_corpus)} entries saved to {rl_corpus_file}')\n",
    "\n",
    "# UI elements\n",
    "layout = widgets.Layout(width='250px', height='50px')\n",
    "download_ls_button = widgets.Button(description=\"Download LibriSpeech Data\", button_style='info', layout=layout, icon='download')\n",
    "download_ls_button.on_click(on_download_ls_button_click)\n",
    "create_rl_button = widgets.Button(description=\"Create ReadyLingua Corpus\", button_style='warning', layout=layout, icon=\"book\", tooltip='~5 minutes')\n",
    "create_rl_button.on_click(on_create_rl_button_click)\n",
    "create_ls_button = widgets.Button(description=\"Create LibriSpeech Corpus\", button_style='warning', layout=layout,icon=\"book\", tooltip='~5 hours')\n",
    "create_ls_button.on_click(on_create_ls_button_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creation of Corpora\n",
    "The alignment information is extracted from the raw files and stored in **corpus_entries**. Those corpus entries can be created in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus entries\n",
    "In order to allow data from all sources for training, it had to be converted to a common format. Since (to my knowledge) there is not a standardized format for FA, I had to define one myself. Therefore I went for the following structure for a single corpus entry:\n",
    "\n",
    "```JSON\n",
    "// definition of the corpus\n",
    "corpus = [corpus_entry]\n",
    "\n",
    "// definition of an individual corpus entry\n",
    "corpus_entry = \n",
    "{\n",
    "    'audio': [byte],                 // bytes from the audio file\n",
    "    'transcription': string,         // raw (unaligned) text \n",
    "    'speech-pauses': [speech_pause], // segmentation of the audio file into speech and pause segments\n",
    "    'alignment': [alignment]         // alignment of bits of the unaligned text with the audio\n",
    "}\n",
    "\n",
    "// definition of a speech or pause segment\n",
    "speech_pause = \n",
    "{\n",
    "    'id': string,                    // some unique identifier\n",
    "    'start': int,                    // start frame of the segment\n",
    "    'end': int,                      // end frame of the speech pause\n",
    "    'class': string                  // 'speech' for a speech segment, 'pause' for a pause segment\n",
    "}\n",
    "\n",
    "// definition of an alignment\n",
    "alignment = \n",
    "{\n",
    "    'text': string,                  // text that is being spoken in the audio\n",
    "    'start': int,                    // start frame in the audio file (when the text starts)\n",
    "    'end': int                       // end frame in the audio file (when the text stops)\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ReadyLingua Corpus\n",
    "ReadyLingua (RL) provides alignment data distributed over several files files:\n",
    "\n",
    "* `*.wav`: Audio file containing the speech\n",
    "* `*.txt`: UTF-8 encoded (unaligned) transcription\n",
    "* `* - Segmentation.xml`: file comtaining the definition of speech- and pause segments\n",
    "```XML\n",
    "<Segmentation>\n",
    "    <SelectionExtension>0</SelectionExtension>\n",
    "    <Segments>\n",
    "\t<Segment id=\"1\" start=\"83790\" end=\"122598\" class=\"Speech\" uid=\"5\" />\n",
    "\t...\n",
    "    </Segments>\n",
    "    <Segmenter SegmenterType=\"SICore.AudioSegmentation.EnergyThresholding\">\n",
    "        <MaxSpeechSegmentExtension>50</MaxSpeechSegmentExtension>\n",
    "        <Length>-1</Length>\n",
    "        <Energies>\n",
    "            <Value id=\"1\" value=\"0\" />\n",
    "            ...\n",
    "        </Energies>\n",
    "        <OriginalSegments>\n",
    "            <Segment id=\"1\" start=\"83790\" end=\"100548\" class=\"Speech\" uid=\"2\" />\n",
    "            ...\n",
    "        </OriginalSegments>\n",
    "        <EnergyPeak>3569753</EnergyPeak>\n",
    "        <StepSize>441</StepSize>\n",
    "        <ITL>146139</ITL>\n",
    "        <ITU>730695</ITU>\n",
    "        <LastUid>2048</LastUid>\n",
    "        <MinPauseDuration>200</MinPauseDuration>\n",
    "        <MinSpeechDuration>150</MinSpeechDuration>\n",
    "        <BeginOfSilence>1546255</BeginOfSilence>\n",
    "        <SilenceLength>100</SilenceLength>\n",
    "        <ThresholdCorrectionFactor>1</ThresholdCorrectionFactor>\n",
    "    </Segmenter>\n",
    "</Segmentation>\n",
    "```\n",
    "* `* - Index.xml`: file containing the actual alignments of text to audio\n",
    "```XML\n",
    "<XMLIndexFile>\n",
    "    <Version>2.0.0</Version>\n",
    "    <SamplingRate>44100</SamplingRate>\n",
    "    <NumberOfIndices>91</NumberOfIndices>\n",
    "    <TextAudioIndex>\n",
    "        <TextStartPos>0</TextStartPos>\n",
    "        <TextEndPos>36</TextEndPos>\n",
    "        <AudioStartPos>952101</AudioStartPos>\n",
    "        <AudioEndPos>1062000</AudioEndPos>\n",
    "        <SpeakerKey>-1</SpeakerKey>\n",
    "    </TextAudioIndex>\n",
    "    ...\n",
    "</XMLIndexFile>    \n",
    "```\n",
    "* `* - Project.xml`: Project file binding the different files together for a corpus entry (note: this file is optional, i.e. there may be not project file for a corpus entry)\n",
    "\n",
    "Corpus entries are organized in a folder hierarchy. There is a fileset for each corpus entry. Usually, the files for a specific corpus entry reside in a leaf directory (i.e. a directory without further subdirectories). If there is a project file, this file is used to locate the files needed to \n",
    "\n",
    "Audio data is provided as Wave-Files with a sampling rate of 44,1 kHz (stereo). Because most ASR corpora provide their recordings with a sampling rate of 16 kHz the files were downsampled and the alignment information adjusted. The raw transcription is integrated as-is. The XML files are parsed to extract the alignment data. Alignment-, textual and downsampled audio data are merged into a corpus entry as described above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus entries\n",
    "We need to extract the alignments from the segmentation information of the raw data. For this, the downloaded data needs to be converted to corpus entries. This process takes a few minuts, so this is a good time to have a coffee break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_rl_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore corpus\n",
    "To see if everything worked as expected let's check out a sample alignment. You can execute the cell below to show a random alignment from a random corpus entry. You can execute the cell several times to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_corpus = load_corpus(rl_corpus_file)\n",
    "show_corpus_entry(rl_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LibriSpeech Corpus\n",
    "[LibriSpeech](http://www.openslr.org/12/) is an open-source corpus for Automatic Speech Recognition (ASR). It contains recordings of LibriVox' public domain audio books and their transcriptions made by volunteers. The data is evenly distributed in terms of gender, recording length, accent, etc. The corpus is split into training-, dev- and test-set (`train-*.tar.gz`, `dev-*.tar.gz` and `test-*.tar.gz`). However, those sets only contain the transcript as a set of segments and an audio file for each segment. They do not contain any temporal information which is needed for alignment.\n",
    "\n",
    "Luckily, there is also the `original-mp3-tar.gz` for download which contains the original LibriVox mp3 files (from which the corpus was created) along with the alignment information. Alignment is made on utterance level, i.e. the transcript is split up into segments whereas each segment corresponds to an utterance. Segments were derived by allowing splitting on every silence interval longer than 300ms. \n",
    "\n",
    "The data is organized into subdirectories of the following format:\n",
    "\n",
    "    ./LibriSpeech/mp3/{speaker_id}/{chapter_id}/\n",
    "\n",
    "There is one subdirectory containing all the information about a recording. For this project the following files are important:\n",
    "\n",
    "- `{chapter_id}.mp3`: The audio file containing the recording. The audio is mono with a bitrate of 128 kB/s and a sampling rate of 44.1 kHz.\n",
    "- `{speaker_id}-{chapter_id}.seg.txt`: Text file containing temporal information about the segments (one segment per line). The time is indicated in seconds.\n",
    "Example:\n",
    "```\n",
    "14-208_0000 25.16 40.51\n",
    "```\n",
    "- `{speaker_id}-{chapter_id}.trans.txt`: Text file containing the transcriptions of the segments (one segment per line). The transcription is all uppercase and does not contain any punctuation.\n",
    "```\n",
    "14-208_0000 CHAPTER ELEVEN THE MORROW BROUGHT A VERY SOBER LOOKING MORNING THE SUN MAKING ONLY A FEW EFFORTS...\n",
    "```\n",
    "\n",
    "In order to create the corpus, these files had to be parsed and the audio was converted and downsampled to a 16kHz Wave-file.\n",
    "Information about the Speakers, Chapters and Books were extracted from the respective files (`SPEAKERS.TXT`, `CHAPTERS.TXT` and `BOOKS.TXT`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Download raw data\n",
    "To create the LibriSpeech corpus you first need to download the raw data. The files are over 80GB and need to be extracted, so this might take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(download_ls_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus\n",
    "We need to extract the alignments from the segmentation information of the raw data. For this, the downloaded data needs to be converted to corpus entries. **This process takes several hours, so you might want to do this just before knocking-off time!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_ls_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Explore corpus\n",
    "To see if everything worked as expected let's check out a sample alignment. You can execute the cell below to show a random alignment from a random corpus entry. You can execute the cell several times to see different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_corpus = load_corpus(ls_corpus_file)\n",
    "show_corpus_entry(ls_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
